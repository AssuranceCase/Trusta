{
    "aws_s3.abstractmethod": "def abstractmethod(funcobj):\n    \"\"\"A decorator indicating abstract methods.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract methods are overridden.\n    The abstract methods can be called using any of the normal\n    'super' call mechanisms.  abstractmethod() may be used to declare\n    abstract methods for properties and descriptors.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractmethod\n            def my_abstract_method(self, ...):\n                ...\n    \"\"\"\n    funcobj.__isabstractmethod__ = True\n    return funcobj\n",
    "aws_s3.disable_signing": "def disable_signing(**kwargs):\n    \"\"\"\n    This handler disables request signing by setting the signer\n    name to a special sentinel value.\n    \"\"\"\n    return botocore.UNSIGNED\n",
    "aws_s3.AWS_S3.__contains__": "    def __contains__(self, file_name):\n        return file_name in (item['name'] for item in self._files)\n",
    "aws_s3.AWS_S3.__init__": "    def __init__(self, bucket, region=None, access_key_id=None, secret_key=None, session_token=None, endpoint_url=None):\n        super().__init__()\n        if all([access_key_id, secret_key, session_token]):\n            self._s3 = boto3.resource(\n                's3',\n                aws_access_key_id=access_key_id,\n                aws_secret_access_key=secret_key,\n                aws_session_token=session_token,\n                region_name=region,\n                endpoint_url=endpoint_url\n            )\n        elif access_key_id and secret_key:\n            self._s3 = boto3.resource(\n                's3',\n                aws_access_key_id=access_key_id,\n                aws_secret_access_key=secret_key,\n                region_name=region,\n                endpoint_url=endpoint_url\n            )\n        elif any([access_key_id, secret_key, session_token]):\n            raise Exception('Insufficient data for authorization')\n        # anonymous access\n        if not any([access_key_id, secret_key, session_token]):\n            self._s3 = boto3.resource('s3', region_name=region, endpoint_url=endpoint_url)\n            self._s3.meta.client.meta.events.register('choose-signer.s3.*', disable_signing)\n        self._client_s3 = self._s3.meta.client\n        self._bucket = self._s3.Bucket(bucket)\n        self.region = region\n",
    "aws_s3.AWS_S3.__len__": "    def __len__(self):\n        return len(self._files)\n",
    "aws_s3.AWS_S3._head": "    def _head(self):\n        return self._client_s3.head_bucket(Bucket=self.name)\n",
    "aws_s3.AWS_S3._head_file": "    def _head_file(self, key):\n        return self._client_s3.head_object(Bucket=self.name, Key=key)\n",
    "aws_s3.AWS_S3.create": "    def create(self):\n        try:\n            responce = self._bucket.create(\n                ACL='private',\n                CreateBucketConfiguration={\n                    'LocationConstraint': self.region,\n                },\n                ObjectLockEnabledForBucket=False\n            )\n            print('Bucket {} has been created on {} region'.format(self.name, responce['Location']))\n        except Exception as ex:\n            msg = str(ex)\n            print(msg)\n            raise Exception(msg)\n",
    "aws_s3.AWS_S3.delete_objects": "    def delete_objects(self, object_name):\n        try:\n            delete_keys = {'Objects': []}\n            delete_keys['Objects'] = [{'Key': obj} for obj in object_name]\n            self._client_s3.delete_objects(Bucket=self.name, Delete=delete_keys)\n        except ClientError as e:\n            print(e)\n            return False\n        return True\n",
    "aws_s3.AWS_S3.download_file": "    def download_file(self, key, path):\n        file_obj = self.download_fileobj(key)\n        if isinstance(file_obj, BytesIO):\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            with open(path, 'wb') as f:\n                f.write(file_obj.getvalue())\n        else:\n            raise NotImplementedError(\"Unsupported type {} was found\".format(type(file_obj)))\n",
    "aws_s3.AWS_S3.download_fileobj": "    def download_fileobj(self, key):\n        key = key.replace(\"\\\\\", \"/\")\n        buf = BytesIO()\n        self.bucket.download_fileobj(\n            Key=key, Fileobj=buf, Config=TransferConfig(max_io_queue=self.transfer_config['max_io_queue'])\n        )\n        buf.seek(0)\n        return buf\n",
    "aws_s3.AWS_S3.get_content": "    def get_content(self, prefix=''):\n        if not prefix:\n            files = self._bucket.objects.all()\n        else:\n            files = self._bucket.objects.filter(Prefix=prefix.replace(\"\\\\\", \"/\"))\n        return [item.key for item in files]\n",
    "aws_s3.AWS_S3.get_file_last_modified": "    def get_file_last_modified(self, key):\n        return self._head_file(key).get('LastModified')\n",
    "aws_s3.AWS_S3.get_file_status": "    def get_file_status(self, key):\n        try:\n            self._head_file(key)\n            return 'AVAILABLE'\n        except ClientError as ex:\n            code = ex.response['Error']['Code']\n            if code == '403':\n                return 'FORBIDDEN'\n            else:\n                return 'NOT_FOUND'\n",
    "aws_s3.AWS_S3.get_status": "    def get_status(self):\n        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object\n        # return only 3 codes: 200, 403, 404\n        try:\n            self._head()\n            return 'AVAILABLE'\n        except ClientError as ex:\n            code = ex.response['Error']['Code']\n            if code == '403':\n                return 'FORBIDDEN'\n            else:\n                return 'NOT_FOUND'\n",
    "aws_s3.AWS_S3.initialize_content": "    def initialize_content(self, prefix=''):\n        files = self._bucket.objects.all()\n        self._files = [{\n            'name': item.key,\n        } for item in files if prefix == item.key[:len(prefix)]]\n",
    "aws_s3.AWS_S3.move_file": "    def move_file(self, src_key, dest_key):\n        # Copy the file\n        copy_source = {\n            'Bucket': self.name,\n            'Key': src_key\n        }\n        try:\n            self._client_s3.copy_object(Bucket=self.name, CopySource=copy_source, Key=dest_key)\n        except:\n            print('move fail.')\n            return\n        \n        # Delete the original file\n        self._client_s3.delete_object(Bucket=self.name, Key=src_key)\n",
    "aws_s3.AWS_S3.upload_file": "    def upload_file(self, file_name, object_name=None):\n        if object_name is None:\n            object_name = os.path.basename(file_name)\n\n        try:\n            self._client_s3.upload_file(file_name, self.name, object_name)\n        except ClientError as e:\n            print(e)\n            return False\n        return True\n",
    "aws_s3.AWS_S3.upload_fileobj": "    def upload_fileobj(self, file_obj, file_name):\n        self._bucket.upload_fileobj(\n            Fileobj=file_obj, Key=file_name, Config=TransferConfig(max_io_queue=self.transfer_config['max_io_queue'])\n        )\n",
    "aws_s3.ClientError.__init__": "    def __init__(self, error_response, operation_name):\n        retry_info = self._get_retry_info(error_response)\n        error = error_response.get('Error', {})\n        msg = self.MSG_TEMPLATE.format(\n            error_code=error.get('Code', 'Unknown'),\n            error_message=error.get('Message', 'Unknown'),\n            operation_name=operation_name,\n            retry_info=retry_info,\n        )\n        super().__init__(msg)\n        self.response = error_response\n        self.operation_name = operation_name\n",
    "aws_s3.ClientError.__reduce__": "    def __reduce__(self):\n        # Subclasses of ClientError's are dynamically generated and\n        # cannot be pickled unless they are attributes of a\n        # module. So at the very least return a ClientError back.\n        return ClientError, (self.response, self.operation_name)\n",
    "aws_s3.ClientError._get_retry_info": "    def _get_retry_info(self, response):\n        retry_info = ''\n        if 'ResponseMetadata' in response:\n            metadata = response['ResponseMetadata']\n            if metadata.get('MaxAttemptsReached', False):\n                if 'RetryAttempts' in metadata:\n                    retry_info = (\n                        f\" (reached max retries: {metadata['RetryAttempts']})\"\n                    )\n        return retry_info\n",
    "aws_s3.TransferConfig.__init__": "    def __init__(\n        self,\n        multipart_threshold=8 * MB,\n        max_concurrency=10,\n        multipart_chunksize=8 * MB,\n        num_download_attempts=5,\n        max_io_queue=100,\n        io_chunksize=256 * KB,\n        use_threads=True,\n        max_bandwidth=None,\n    ):\n        \"\"\"Configuration object for managed S3 transfers\n\n        :param multipart_threshold: The transfer size threshold for which\n            multipart uploads, downloads, and copies will automatically be\n            triggered.\n\n        :param max_concurrency: The maximum number of threads that will be\n            making requests to perform a transfer. If ``use_threads`` is\n            set to ``False``, the value provided is ignored as the transfer\n            will only ever use the main thread.\n\n        :param multipart_chunksize: The partition size of each part for a\n            multipart transfer.\n\n        :param num_download_attempts: The number of download attempts that\n            will be retried upon errors with downloading an object in S3.\n            Note that these retries account for errors that occur when\n            streaming  down the data from s3 (i.e. socket errors and read\n            timeouts that occur after receiving an OK response from s3).\n            Other retryable exceptions such as throttling errors and 5xx\n            errors are already retried by botocore (this default is 5). This\n            does not take into account the number of exceptions retried by\n            botocore.\n\n        :param max_io_queue: The maximum amount of read parts that can be\n            queued in memory to be written for a download. The size of each\n            of these read parts is at most the size of ``io_chunksize``.\n\n        :param io_chunksize: The max size of each chunk in the io queue.\n            Currently, this is size used when ``read`` is called on the\n            downloaded stream as well.\n\n        :param use_threads: If True, threads will be used when performing\n            S3 transfers. If False, no threads will be used in\n            performing transfers; all logic will be run in the main thread.\n\n        :param max_bandwidth: The maximum bandwidth that will be consumed\n            in uploading and downloading file content. The value is an integer\n            in terms of bytes per second.\n        \"\"\"\n        super().__init__(\n            multipart_threshold=multipart_threshold,\n            max_request_concurrency=max_concurrency,\n            multipart_chunksize=multipart_chunksize,\n            num_download_attempts=num_download_attempts,\n            max_io_queue_size=max_io_queue,\n            io_chunksize=io_chunksize,\n            max_bandwidth=max_bandwidth,\n        )\n        # Some of the argument names are not the same as the inherited\n        # S3TransferConfig so we add aliases so you can still access the\n        # old version of the names.\n        for alias in self.ALIAS:\n            setattr(self, alias, getattr(self, self.ALIAS[alias]))\n        self.use_threads = use_threads\n",
    "aws_s3.TransferConfig.__setattr__": "    def __setattr__(self, name, value):\n        # If the alias name is used, make sure we set the name that it points\n        # to as that is what actually is used in governing the TransferManager.\n        if name in self.ALIAS:\n            super().__setattr__(self.ALIAS[name], value)\n        # Always set the value of the actual name provided.\n        super().__setattr__(name, value)\n",
    "aws_s3.TransferConfig._validate_attrs_are_nonzero": "    def _validate_attrs_are_nonzero(self):\n        for attr, attr_val in self.__dict__.items():\n            if attr_val is not None and attr_val <= 0:\n                raise ValueError(\n                    'Provided parameter %s of value %s must be greater than '\n                    '0.' % (attr, attr_val)\n                )\n",
    "aws_s3._CloudStorage.__contains__": "    def __contains__(self, file_name):\n        return file_name in (item['name'] for item in self._files)\n",
    "aws_s3._CloudStorage.__init__": "    def __init__(self):\n        self._files = []\n",
    "aws_s3._CloudStorage.__len__": "    def __len__(self):\n        return len(self._files)\n",
    "aws_s3._CloudStorage._head": "    @abstractmethod\n    def _head(self):\n        pass\n",
    "aws_s3._CloudStorage._head_file": "    @abstractmethod\n    def _head_file(self, key):\n        pass\n",
    "aws_s3._CloudStorage.create": "    @abstractmethod\n    def create(self):\n        pass\n",
    "aws_s3._CloudStorage.download_file": "    def download_file(self, key, path):\n        file_obj = self.download_fileobj(key)\n        if isinstance(file_obj, BytesIO):\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            with open(path, 'wb') as f:\n                f.write(file_obj.getvalue())\n        else:\n            raise NotImplementedError(\"Unsupported type {} was found\".format(type(file_obj)))\n",
    "aws_s3._CloudStorage.download_fileobj": "    @abstractmethod\n    def download_fileobj(self, key):\n        pass\n",
    "aws_s3._CloudStorage.get_file_last_modified": "    @abstractmethod\n    def get_file_last_modified(self, key):\n        pass\n",
    "aws_s3._CloudStorage.get_file_status": "    @abstractmethod\n    def get_file_status(self, key):\n        pass\n",
    "aws_s3._CloudStorage.get_status": "    @abstractmethod\n    def get_status(self):\n        pass\n",
    "aws_s3._CloudStorage.initialize_content": "    @abstractmethod\n    def initialize_content(self):\n        pass\n",
    "aws_s3._CloudStorage.upload_file": "    @abstractmethod\n    def upload_file(self, file_obj, file_name):\n        pass\n",
    "common.async_fun": "def async_fun(f):\n\n    def inner_fun(*args, **kwargs):\n\n        t = Thread(target=f, args=args, kwargs=kwargs)\n        t.start()\n\n    return inner_fun\n",
    "common.get_logger": "def get_logger():\n    # \u521b\u5efa\u65e5\u5fd7\u5668\u5bf9\u8c61\n    logger = logging.getLogger(__name__)\n\n    # \u8bbe\u7f6elogger\u53ef\u8f93\u51fa\u65e5\u5fd7\u7ea7\u522b\u8303\u56f4\n    logger.setLevel(logging.DEBUG)\n\n    # \u6dfb\u52a0\u63a7\u5236\u53f0handler\uff0c\u7528\u4e8e\u8f93\u51fa\u65e5\u5fd7\u5230\u63a7\u5236\u53f0\n    console_handler = logging.StreamHandler()\n\n    # \u6dfb\u52a0\u65e5\u5fd7\u6587\u4ef6handler\uff0c\u7528\u4e8e\u8f93\u51fa\u65e5\u5fd7\u5230\u6587\u4ef6\u4e2d\n    # file_handler = logging.FileHandler(filename='log.txt', encoding='UTF-8')\n    # \u6dfb\u52a0\u65e5\u5fd7\u6587\u4ef6handler\uff0c\u7528\u4e8e\u8f93\u51fa\u65e5\u5fd7\u5230\u6587\u4ef6\u4e2d, \u6309\u65f6\u95f4\u5bf9\u6587\u4ef6\u8fdb\u884c\u5207\u5272\n    os.makedirs('log_file', exist_ok=True)\n    timefile_handler = TimedRotatingFileHandler(\n        filename='log_file/time_log.txt',\n        when=\"D\", interval=7, # \u6bcf7\u5929\u521b\u5efa\u4e00\u4e2a\u6587\u4ef6\u3002\n        backupCount=365//7, # \u5907\u4efd1\u5e74\u7684\u65e5\u5fd7\n        encoding=\"utf8\"\n    )\n\n    # \u5c06handler\u6dfb\u52a0\u5230\u65e5\u5fd7\u5668\u4e2d\n    logger.addHandler(console_handler)\n    logger.addHandler(timefile_handler)\n\n    # \u8bbe\u7f6e\u683c\u5f0f\u5e76\u8d4b\u4e88handler\n    formatter = logging.Formatter(\"[%(asctime)s pid:%(process)d %(filename)s:%(lineno)d]: %(message)s\",\n                                datefmt=\"%m/%d %H:%M:%S\")\n    console_handler.setFormatter(formatter)\n    timefile_handler.setFormatter(formatter)\n\n    return logger\n",
    "common.set_job_field": "def set_job_field(job_uuid, dict_update):\n    url = '{}/api/job/{}/'.format(JOB_HOST, job_uuid)\n    r = requests.patch(url, data=dict_update)\n    print(r.text)\n",
    "common.PostLog.__call__": "    def __call__(self, level, msg):\n        # if level == 'INFO':\n        #     return\n        if level == 'DEBUG':\n            self.logger.debug(msg)\n        if level == 'INFO':\n            self.logger.info(msg)\n        if level == 'WARNING':\n            self.logger.warning(msg)\n        if level == 'ERROR':\n            self.logger.error(msg)\n        if level == 'CRITICAL':\n            self.logger.critical(msg)\n\n        if self.job_id != '' and level in ['ERROR', 'WARNING', 'CRITICAL']:\n            self.post_log(msg, self.job_id, level)\n",
    "common.PostLog.__init__": "    def __init__(self, job_id):\n        print('PostLog init, job_id=', job_id)\n        self.job_id = job_id\n        self.logger = S_LOGGER\n",
    "common.PostLog.post_log": "    def post_log(self, msg, job_id, level=\"INFO\"):\n        # print(msg)\n        url = f'{JOB_HOST}/api/log/'\n        data = {\n            \"level\": 'INFO',\n            \"log_text\": '> ' + msg,\n            \"job\": job_id\n        }\n        if level != 'ERROR':\n            data['level'] = level\n            requests.post(url, data=data)\n        else:\n            requests.post(url, data=data)\n            data['level'] = 'ERROR'\n            data['log_text'] = \"-\" * 40 + \"infer ERROR end\" + \"-\" * 40\n            requests.post(url, data=data)\n",
    "common.Thread.__init__": "    def __init__(self, group=None, target=None, name=None,\n                 args=(), kwargs=None, *, daemon=None):\n        \"\"\"This constructor should always be called with keyword arguments. Arguments are:\n\n        *group* should be None; reserved for future extension when a ThreadGroup\n        class is implemented.\n\n        *target* is the callable object to be invoked by the run()\n        method. Defaults to None, meaning nothing is called.\n\n        *name* is the thread name. By default, a unique name is constructed of\n        the form \"Thread-N\" where N is a small decimal number.\n\n        *args* is the argument tuple for the target invocation. Defaults to ().\n\n        *kwargs* is a dictionary of keyword arguments for the target\n        invocation. Defaults to {}.\n\n        If a subclass overrides the constructor, it must make sure to invoke\n        the base class constructor (Thread.__init__()) before doing anything\n        else to the thread.\n\n        \"\"\"\n        assert group is None, \"group argument must be None for now\"\n        if kwargs is None:\n            kwargs = {}\n        self._target = target\n        self._name = str(name or _newname())\n        self._args = args\n        self._kwargs = kwargs\n        if daemon is not None:\n            self._daemonic = daemon\n        else:\n            self._daemonic = current_thread().daemon\n        self._ident = None\n        if _HAVE_THREAD_NATIVE_ID:\n            self._native_id = None\n        self._tstate_lock = None\n        self._started = Event()\n        self._is_stopped = False\n        self._initialized = True\n        # Copy of sys.stderr used by self._invoke_excepthook()\n        self._stderr = _sys.stderr\n        self._invoke_excepthook = _make_invoke_excepthook()\n        # For debugging and _after_fork()\n        _dangling.add(self)\n",
    "common.Thread.__repr__": "    def __repr__(self):\n        assert self._initialized, \"Thread.__init__() was not called\"\n        status = \"initial\"\n        if self._started.is_set():\n            status = \"started\"\n        self.is_alive() # easy way to get ._is_stopped set when appropriate\n        if self._is_stopped:\n            status = \"stopped\"\n        if self._daemonic:\n            status += \" daemon\"\n        if self._ident is not None:\n            status += \" %s\" % self._ident\n        return \"<%s(%s, %s)>\" % (self.__class__.__name__, self._name, status)\n",
    "common.Thread._bootstrap": "    def _bootstrap(self):\n        # Wrapper around the real bootstrap code that ignores\n        # exceptions during interpreter cleanup.  Those typically\n        # happen when a daemon thread wakes up at an unfortunate\n        # moment, finds the world around it destroyed, and raises some\n        # random exception *** while trying to report the exception in\n        # _bootstrap_inner() below ***.  Those random exceptions\n        # don't help anybody, and they confuse users, so we suppress\n        # them.  We suppress them only when it appears that the world\n        # indeed has already been destroyed, so that exceptions in\n        # _bootstrap_inner() during normal business hours are properly\n        # reported.  Also, we only suppress them for daemonic threads;\n        # if a non-daemonic encounters this, something else is wrong.\n        try:\n            self._bootstrap_inner()\n        except:\n            if self._daemonic and _sys is None:\n                return\n            raise\n",
    "common.Thread._bootstrap_inner": "    def _bootstrap_inner(self):\n        try:\n            self._set_ident()\n            self._set_tstate_lock()\n            if _HAVE_THREAD_NATIVE_ID:\n                self._set_native_id()\n            self._started.set()\n            with _active_limbo_lock:\n                _active[self._ident] = self\n                del _limbo[self]\n\n            if _trace_hook:\n                _sys.settrace(_trace_hook)\n            if _profile_hook:\n                _sys.setprofile(_profile_hook)\n\n            try:\n                self.run()\n            except:\n                self._invoke_excepthook(self)\n        finally:\n            with _active_limbo_lock:\n                try:\n                    # We don't call self._delete() because it also\n                    # grabs _active_limbo_lock.\n                    del _active[get_ident()]\n                except:\n                    pass\n",
    "common.Thread._delete": "    def _delete(self):\n        \"Remove current thread from the dict of currently running threads.\"\n        with _active_limbo_lock:\n            del _active[get_ident()]\n",
    "common.Thread._reset_internal_locks": "    def _reset_internal_locks(self, is_alive):\n        # private!  Called by _after_fork() to reset our internal locks as\n        # they may be in an invalid state leading to a deadlock or crash.\n        self._started._reset_internal_locks()\n        if is_alive:\n            self._set_tstate_lock()\n        else:\n            # The thread isn't alive after fork: it doesn't have a tstate\n            # anymore.\n            self._is_stopped = True\n            self._tstate_lock = None\n",
    "common.Thread._set_ident": "    def _set_ident(self):\n        self._ident = get_ident()\n",
    "common.Thread._set_native_id": "        def _set_native_id(self):\n            self._native_id = get_native_id()\n",
    "common.Thread._set_tstate_lock": "    def _set_tstate_lock(self):\n        \"\"\"\n        Set a lock object which will be released by the interpreter when\n        the underlying thread state (see pystate.h) gets deleted.\n        \"\"\"\n        self._tstate_lock = _set_sentinel()\n        self._tstate_lock.acquire()\n\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                _shutdown_locks.add(self._tstate_lock)\n",
    "common.Thread._stop": "    def _stop(self):\n        # After calling ._stop(), .is_alive() returns False and .join() returns\n        # immediately.  ._tstate_lock must be released before calling ._stop().\n        #\n        # Normal case:  C code at the end of the thread's life\n        # (release_sentinel in _threadmodule.c) releases ._tstate_lock, and\n        # that's detected by our ._wait_for_tstate_lock(), called by .join()\n        # and .is_alive().  Any number of threads _may_ call ._stop()\n        # simultaneously (for example, if multiple threads are blocked in\n        # .join() calls), and they're not serialized.  That's harmless -\n        # they'll just make redundant rebindings of ._is_stopped and\n        # ._tstate_lock.  Obscure:  we rebind ._tstate_lock last so that the\n        # \"assert self._is_stopped\" in ._wait_for_tstate_lock() always works\n        # (the assert is executed only if ._tstate_lock is None).\n        #\n        # Special case:  _main_thread releases ._tstate_lock via this\n        # module's _shutdown() function.\n        lock = self._tstate_lock\n        if lock is not None:\n            assert not lock.locked()\n        self._is_stopped = True\n        self._tstate_lock = None\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                _shutdown_locks.discard(lock)\n",
    "common.Thread._wait_for_tstate_lock": "    def _wait_for_tstate_lock(self, block=True, timeout=-1):\n        # Issue #18808: wait for the thread state to be gone.\n        # At the end of the thread's life, after all knowledge of the thread\n        # is removed from C data structures, C code releases our _tstate_lock.\n        # This method passes its arguments to _tstate_lock.acquire().\n        # If the lock is acquired, the C code is done, and self._stop() is\n        # called.  That sets ._is_stopped to True, and ._tstate_lock to None.\n        lock = self._tstate_lock\n        if lock is None:  # already determined that the C code is done\n            assert self._is_stopped\n        elif lock.acquire(block, timeout):\n            lock.release()\n            self._stop()\n",
    "common.Thread.getName": "    def getName(self):\n        return self.name\n",
    "common.Thread.isAlive": "    def isAlive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method is deprecated, use is_alive() instead.\n        \"\"\"\n        import warnings\n        warnings.warn('isAlive() is deprecated, use is_alive() instead',\n                      DeprecationWarning, stacklevel=2)\n        return self.is_alive()\n",
    "common.Thread.isDaemon": "    def isDaemon(self):\n        return self.daemon\n",
    "common.Thread.is_alive": "    def is_alive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method returns True just before the run() method starts until just\n        after the run() method terminates. The module function enumerate()\n        returns a list of all alive threads.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        if self._is_stopped or not self._started.is_set():\n            return False\n        self._wait_for_tstate_lock(False)\n        return not self._is_stopped\n",
    "common.Thread.join": "    def join(self, timeout=None):\n        \"\"\"Wait until the thread terminates.\n\n        This blocks the calling thread until the thread whose join() method is\n        called terminates -- either normally or through an unhandled exception\n        or until the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof). As join() always returns None, you must call\n        is_alive() after join() to decide whether a timeout happened -- if the\n        thread is still alive, the join() call timed out.\n\n        When the timeout argument is not present or None, the operation will\n        block until the thread terminates.\n\n        A thread can be join()ed many times.\n\n        join() raises a RuntimeError if an attempt is made to join the current\n        thread as that would cause a deadlock. It is also an error to join() a\n        thread before it has been started and attempts to do so raises the same\n        exception.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if not self._started.is_set():\n            raise RuntimeError(\"cannot join thread before it is started\")\n        if self is current_thread():\n            raise RuntimeError(\"cannot join current thread\")\n\n        if timeout is None:\n            self._wait_for_tstate_lock()\n        else:\n            # the behavior of a negative timeout isn't documented, but\n            # historically .join(timeout=x) for x<0 has acted as if timeout=0\n            self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
    "common.Thread.run": "    def run(self):\n        \"\"\"Method representing the thread's activity.\n\n        You may override this method in a subclass. The standard run() method\n        invokes the callable object passed to the object's constructor as the\n        target argument, if any, with sequential and keyword arguments taken\n        from the args and kwargs arguments, respectively.\n\n        \"\"\"\n        try:\n            if self._target:\n                self._target(*self._args, **self._kwargs)\n        finally:\n            # Avoid a refcycle if the thread is running a function with\n            # an argument that has a member that points to the thread.\n            del self._target, self._args, self._kwargs\n",
    "common.Thread.setDaemon": "    def setDaemon(self, daemonic):\n        self.daemon = daemonic\n",
    "common.Thread.setName": "    def setName(self, name):\n        self.name = name\n",
    "common.Thread.start": "    def start(self):\n        \"\"\"Start the thread's activity.\n\n        It must be called at most once per thread object. It arranges for the\n        object's run() method to be invoked in a separate thread of control.\n\n        This method will raise a RuntimeError if called more than once on the\n        same thread object.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"thread.__init__() not called\")\n\n        if self._started.is_set():\n            raise RuntimeError(\"threads can only be started once\")\n        with _active_limbo_lock:\n            _limbo[self] = self\n        try:\n            _start_new_thread(self._bootstrap, ())\n        except Exception:\n            with _active_limbo_lock:\n                del _limbo[self]\n            raise\n        self._started.wait()\n",
    "common.TimedRotatingFileHandler.__init__": "    def __init__(self, filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None):\n        BaseRotatingHandler.__init__(self, filename, 'a', encoding, delay)\n        self.when = when.upper()\n        self.backupCount = backupCount\n        self.utc = utc\n        self.atTime = atTime\n        # Calculate the real rollover interval, which is just the number of\n        # seconds between rollovers.  Also set the filename suffix used when\n        # a rollover occurs.  Current 'when' events supported:\n        # S - Seconds\n        # M - Minutes\n        # H - Hours\n        # D - Days\n        # midnight - roll over at midnight\n        # W{0-6} - roll over on a certain day; 0 - Monday\n        #\n        # Case of the 'when' specifier is not important; lower or upper case\n        # will work.\n        if self.when == 'S':\n            self.interval = 1 # one second\n            self.suffix = \"%Y-%m-%d_%H-%M-%S\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n        elif self.when == 'M':\n            self.interval = 60 # one minute\n            self.suffix = \"%Y-%m-%d_%H-%M\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}(\\.\\w+)?$\"\n        elif self.when == 'H':\n            self.interval = 60 * 60 # one hour\n            self.suffix = \"%Y-%m-%d_%H\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}_\\d{2}(\\.\\w+)?$\"\n        elif self.when == 'D' or self.when == 'MIDNIGHT':\n            self.interval = 60 * 60 * 24 # one day\n            self.suffix = \"%Y-%m-%d\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n        elif self.when.startswith('W'):\n            self.interval = 60 * 60 * 24 * 7 # one week\n            if len(self.when) != 2:\n                raise ValueError(\"You must specify a day for weekly rollover from 0 to 6 (0 is Monday): %s\" % self.when)\n            if self.when[1] < '0' or self.when[1] > '6':\n                raise ValueError(\"Invalid day specified for weekly rollover: %s\" % self.when)\n            self.dayOfWeek = int(self.when[1])\n            self.suffix = \"%Y-%m-%d\"\n            self.extMatch = r\"^\\d{4}-\\d{2}-\\d{2}(\\.\\w+)?$\"\n        else:\n            raise ValueError(\"Invalid rollover interval specified: %s\" % self.when)\n\n        self.extMatch = re.compile(self.extMatch, re.ASCII)\n        self.interval = self.interval * interval # multiply by units requested\n        # The following line added because the filename passed in could be a\n        # path object (see Issue #27493), but self.baseFilename will be a string\n        filename = self.baseFilename\n        if os.path.exists(filename):\n            t = os.stat(filename)[ST_MTIME]\n        else:\n            t = int(time.time())\n        self.rolloverAt = self.computeRollover(t)\n",
    "common.TimedRotatingFileHandler.__repr__": "    def __repr__(self):\n        level = getLevelName(self.level)\n        return '<%s %s (%s)>' % (self.__class__.__name__, self.baseFilename, level)\n",
    "common.TimedRotatingFileHandler._open": "    def _open(self):\n        \"\"\"\n        Open the current base file with the (original) mode and encoding.\n        Return the resulting stream.\n        \"\"\"\n        return open(self.baseFilename, self.mode, encoding=self.encoding)\n",
    "common.TimedRotatingFileHandler.acquire": "    def acquire(self):\n        \"\"\"\n        Acquire the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.acquire()\n",
    "common.TimedRotatingFileHandler.addFilter": "    def addFilter(self, filter):\n        \"\"\"\n        Add the specified filter to this handler.\n        \"\"\"\n        if not (filter in self.filters):\n            self.filters.append(filter)\n",
    "common.TimedRotatingFileHandler.close": "    def close(self):\n        \"\"\"\n        Closes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            try:\n                if self.stream:\n                    try:\n                        self.flush()\n                    finally:\n                        stream = self.stream\n                        self.stream = None\n                        if hasattr(stream, \"close\"):\n                            stream.close()\n            finally:\n                # Issue #19523: call unconditionally to\n                # prevent a handler leak when delay is set\n                StreamHandler.close(self)\n        finally:\n            self.release()\n",
    "common.TimedRotatingFileHandler.computeRollover": "    def computeRollover(self, currentTime):\n        \"\"\"\n        Work out the rollover time based on the specified time.\n        \"\"\"\n        result = currentTime + self.interval\n        # If we are rolling over at midnight or weekly, then the interval is already known.\n        # What we need to figure out is WHEN the next interval is.  In other words,\n        # if you are rolling over at midnight, then your base interval is 1 day,\n        # but you want to start that one day clock at midnight, not now.  So, we\n        # have to fudge the rolloverAt value in order to trigger the first rollover\n        # at the right time.  After that, the regular interval will take care of\n        # the rest.  Note that this code doesn't care about leap seconds. :)\n        if self.when == 'MIDNIGHT' or self.when.startswith('W'):\n            # This could be done with less code, but I wanted it to be clear\n            if self.utc:\n                t = time.gmtime(currentTime)\n            else:\n                t = time.localtime(currentTime)\n            currentHour = t[3]\n            currentMinute = t[4]\n            currentSecond = t[5]\n            currentDay = t[6]\n            # r is the number of seconds left between now and the next rotation\n            if self.atTime is None:\n                rotate_ts = _MIDNIGHT\n            else:\n                rotate_ts = ((self.atTime.hour * 60 + self.atTime.minute)*60 +\n                    self.atTime.second)\n\n            r = rotate_ts - ((currentHour * 60 + currentMinute) * 60 +\n                currentSecond)\n            if r < 0:\n                # Rotate time is before the current time (for example when\n                # self.rotateAt is 13:45 and it now 14:15), rotation is\n                # tomorrow.\n                r += _MIDNIGHT\n                currentDay = (currentDay + 1) % 7\n            result = currentTime + r\n            # If we are rolling over on a certain day, add in the number of days until\n            # the next rollover, but offset by 1 since we just calculated the time\n            # until the next day starts.  There are three cases:\n            # Case 1) The day to rollover is today; in this case, do nothing\n            # Case 2) The day to rollover is further in the interval (i.e., today is\n            #         day 2 (Wednesday) and rollover is on day 6 (Sunday).  Days to\n            #         next rollover is simply 6 - 2 - 1, or 3.\n            # Case 3) The day to rollover is behind us in the interval (i.e., today\n            #         is day 5 (Saturday) and rollover is on day 3 (Thursday).\n            #         Days to rollover is 6 - 5 + 3, or 4.  In this case, it's the\n            #         number of days left in the current week (1) plus the number\n            #         of days in the next week until the rollover day (3).\n            # The calculations described in 2) and 3) above need to have a day added.\n            # This is because the above time calculation takes us to midnight on this\n            # day, i.e. the start of the next day.\n            if self.when.startswith('W'):\n                day = currentDay # 0 is Monday\n                if day != self.dayOfWeek:\n                    if day < self.dayOfWeek:\n                        daysToWait = self.dayOfWeek - day\n                    else:\n                        daysToWait = 6 - day + self.dayOfWeek + 1\n                    newRolloverAt = result + (daysToWait * (60 * 60 * 24))\n                    if not self.utc:\n                        dstNow = t[-1]\n                        dstAtRollover = time.localtime(newRolloverAt)[-1]\n                        if dstNow != dstAtRollover:\n                            if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                                addend = -3600\n                            else:           # DST bows out before next rollover, so we need to add an hour\n                                addend = 3600\n                            newRolloverAt += addend\n                    result = newRolloverAt\n        return result\n",
    "common.TimedRotatingFileHandler.createLock": "    def createLock(self):\n        \"\"\"\n        Acquire a thread lock for serializing access to the underlying I/O.\n        \"\"\"\n        self.lock = threading.RLock()\n        _register_at_fork_reinit_lock(self)\n",
    "common.TimedRotatingFileHandler.doRollover": "    def doRollover(self):\n        \"\"\"\n        do a rollover; in this case, a date/time stamp is appended to the filename\n        when the rollover happens.  However, you want the file to be named for the\n        start of the interval, not the current time.  If there is a backup count,\n        then we have to get a list of matching filenames, sort them and remove\n        the one with the oldest suffix.\n        \"\"\"\n        if self.stream:\n            self.stream.close()\n            self.stream = None\n        # get the time that this sequence started at and make it a TimeTuple\n        currentTime = int(time.time())\n        dstNow = time.localtime(currentTime)[-1]\n        t = self.rolloverAt - self.interval\n        if self.utc:\n            timeTuple = time.gmtime(t)\n        else:\n            timeTuple = time.localtime(t)\n            dstThen = timeTuple[-1]\n            if dstNow != dstThen:\n                if dstNow:\n                    addend = 3600\n                else:\n                    addend = -3600\n                timeTuple = time.localtime(t + addend)\n        dfn = self.rotation_filename(self.baseFilename + \".\" +\n                                     time.strftime(self.suffix, timeTuple))\n        if os.path.exists(dfn):\n            os.remove(dfn)\n        self.rotate(self.baseFilename, dfn)\n        if self.backupCount > 0:\n            for s in self.getFilesToDelete():\n                os.remove(s)\n        if not self.delay:\n            self.stream = self._open()\n        newRolloverAt = self.computeRollover(currentTime)\n        while newRolloverAt <= currentTime:\n            newRolloverAt = newRolloverAt + self.interval\n        #If DST changes and midnight or weekly rollover, adjust for this.\n        if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n            dstAtRollover = time.localtime(newRolloverAt)[-1]\n            if dstNow != dstAtRollover:\n                if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                    addend = -3600\n                else:           # DST bows out before next rollover, so we need to add an hour\n                    addend = 3600\n                newRolloverAt += addend\n        self.rolloverAt = newRolloverAt\n",
    "common.TimedRotatingFileHandler.emit": "    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        Output the record to the file, catering for rollover as described\n        in doRollover().\n        \"\"\"\n        try:\n            if self.shouldRollover(record):\n                self.doRollover()\n            logging.FileHandler.emit(self, record)\n        except Exception:\n            self.handleError(record)\n",
    "common.TimedRotatingFileHandler.filter": "    def filter(self, record):\n        \"\"\"\n        Determine if a record is loggable by consulting all the filters.\n\n        The default is to allow the record to be logged; any filter can veto\n        this and the record is then dropped. Returns a zero value if a record\n        is to be dropped, else non-zero.\n\n        .. versionchanged:: 3.2\n\n           Allow filters to be just callables.\n        \"\"\"\n        rv = True\n        for f in self.filters:\n            if hasattr(f, 'filter'):\n                result = f.filter(record)\n            else:\n                result = f(record) # assume callable - will raise if not\n            if not result:\n                rv = False\n                break\n        return rv\n",
    "common.TimedRotatingFileHandler.flush": "    def flush(self):\n        \"\"\"\n        Flushes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.stream and hasattr(self.stream, \"flush\"):\n                self.stream.flush()\n        finally:\n            self.release()\n",
    "common.TimedRotatingFileHandler.format": "    def format(self, record):\n        \"\"\"\n        Format the specified record.\n\n        If a formatter is set, use it. Otherwise, use the default formatter\n        for the module.\n        \"\"\"\n        if self.formatter:\n            fmt = self.formatter\n        else:\n            fmt = _defaultFormatter\n        return fmt.format(record)\n",
    "common.TimedRotatingFileHandler.getFilesToDelete": "    def getFilesToDelete(self):\n        \"\"\"\n        Determine the files to delete when rolling over.\n\n        More specific than the earlier method, which just used glob.glob().\n        \"\"\"\n        dirName, baseName = os.path.split(self.baseFilename)\n        fileNames = os.listdir(dirName)\n        result = []\n        prefix = baseName + \".\"\n        plen = len(prefix)\n        for fileName in fileNames:\n            if fileName[:plen] == prefix:\n                suffix = fileName[plen:]\n                if self.extMatch.match(suffix):\n                    result.append(os.path.join(dirName, fileName))\n        if len(result) < self.backupCount:\n            result = []\n        else:\n            result.sort()\n            result = result[:len(result) - self.backupCount]\n        return result\n",
    "common.TimedRotatingFileHandler.get_name": "    def get_name(self):\n        return self._name\n",
    "common.TimedRotatingFileHandler.handle": "    def handle(self, record):\n        \"\"\"\n        Conditionally emit the specified logging record.\n\n        Emission depends on filters which may have been added to the handler.\n        Wrap the actual emission of the record with acquisition/release of\n        the I/O thread lock. Returns whether the filter passed the record for\n        emission.\n        \"\"\"\n        rv = self.filter(record)\n        if rv:\n            self.acquire()\n            try:\n                self.emit(record)\n            finally:\n                self.release()\n        return rv\n",
    "common.TimedRotatingFileHandler.handleError": "    def handleError(self, record):\n        \"\"\"\n        Handle errors which occur during an emit() call.\n\n        This method should be called from handlers when an exception is\n        encountered during an emit() call. If raiseExceptions is false,\n        exceptions get silently ignored. This is what is mostly wanted\n        for a logging system - most users will not care about errors in\n        the logging system, they are more interested in application errors.\n        You could, however, replace this with a custom handler if you wish.\n        The record which was being processed is passed in to this method.\n        \"\"\"\n        if raiseExceptions and sys.stderr:  # see issue 13807\n            t, v, tb = sys.exc_info()\n            try:\n                sys.stderr.write('--- Logging error ---\\n')\n                traceback.print_exception(t, v, tb, None, sys.stderr)\n                sys.stderr.write('Call stack:\\n')\n                # Walk the stack frame up until we're out of logging,\n                # so as to print the calling context.\n                frame = tb.tb_frame\n                while (frame and os.path.dirname(frame.f_code.co_filename) ==\n                       __path__[0]):\n                    frame = frame.f_back\n                if frame:\n                    traceback.print_stack(frame, file=sys.stderr)\n                else:\n                    # couldn't find the right stack frame, for some reason\n                    sys.stderr.write('Logged from file %s, line %s\\n' % (\n                                     record.filename, record.lineno))\n                # Issue 18671: output logging message and arguments\n                try:\n                    sys.stderr.write('Message: %r\\n'\n                                     'Arguments: %s\\n' % (record.msg,\n                                                          record.args))\n                except RecursionError:  # See issue 36272\n                    raise\n                except Exception:\n                    sys.stderr.write('Unable to print the message and arguments'\n                                     ' - possible formatting error.\\nUse the'\n                                     ' traceback above to help find the error.\\n'\n                                    )\n            except OSError: #pragma: no cover\n                pass    # see issue 5971\n            finally:\n                del t, v, tb\n",
    "common.TimedRotatingFileHandler.release": "    def release(self):\n        \"\"\"\n        Release the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.release()\n",
    "common.TimedRotatingFileHandler.removeFilter": "    def removeFilter(self, filter):\n        \"\"\"\n        Remove the specified filter from this handler.\n        \"\"\"\n        if filter in self.filters:\n            self.filters.remove(filter)\n",
    "common.TimedRotatingFileHandler.rotate": "    def rotate(self, source, dest):\n        \"\"\"\n        When rotating, rotate the current log.\n\n        The default implementation calls the 'rotator' attribute of the\n        handler, if it's callable, passing the source and dest arguments to\n        it. If the attribute isn't callable (the default is None), the source\n        is simply renamed to the destination.\n\n        :param source: The source filename. This is normally the base\n                       filename, e.g. 'test.log'\n        :param dest:   The destination filename. This is normally\n                       what the source is rotated to, e.g. 'test.log.1'.\n        \"\"\"\n        if not callable(self.rotator):\n            # Issue 18940: A file may not have been created if delay is True.\n            if os.path.exists(source):\n                os.rename(source, dest)\n        else:\n            self.rotator(source, dest)\n",
    "common.TimedRotatingFileHandler.rotation_filename": "    def rotation_filename(self, default_name):\n        \"\"\"\n        Modify the filename of a log file when rotating.\n\n        This is provided so that a custom filename can be provided.\n\n        The default implementation calls the 'namer' attribute of the\n        handler, if it's callable, passing the default name to\n        it. If the attribute isn't callable (the default is None), the name\n        is returned unchanged.\n\n        :param default_name: The default name for the log file.\n        \"\"\"\n        if not callable(self.namer):\n            result = default_name\n        else:\n            result = self.namer(default_name)\n        return result\n",
    "common.TimedRotatingFileHandler.setFormatter": "    def setFormatter(self, fmt):\n        \"\"\"\n        Set the formatter for this handler.\n        \"\"\"\n        self.formatter = fmt\n",
    "common.TimedRotatingFileHandler.setLevel": "    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this handler.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n",
    "common.TimedRotatingFileHandler.setStream": "    def setStream(self, stream):\n        \"\"\"\n        Sets the StreamHandler's stream to the specified value,\n        if it is different.\n\n        Returns the old stream, if the stream was changed, or None\n        if it wasn't.\n        \"\"\"\n        if stream is self.stream:\n            result = None\n        else:\n            result = self.stream\n            self.acquire()\n            try:\n                self.flush()\n                self.stream = stream\n            finally:\n                self.release()\n        return result\n",
    "common.TimedRotatingFileHandler.set_name": "    def set_name(self, name):\n        _acquireLock()\n        try:\n            if self._name in _handlers:\n                del _handlers[self._name]\n            self._name = name\n            if name:\n                _handlers[name] = self\n        finally:\n            _releaseLock()\n",
    "common.TimedRotatingFileHandler.shouldRollover": "    def shouldRollover(self, record):\n        \"\"\"\n        Determine if rollover should occur.\n\n        record is not used, as we are just comparing times, but it is needed so\n        the method signatures are the same\n        \"\"\"\n        t = int(time.time())\n        if t >= self.rolloverAt:\n            return 1\n        return 0\n",
    "infer.CallGraphInfer": "def CallGraphInfer(context, event):\n    config = Config()\n    # \u5173\u7cfb\u56fe\u4e2d\u5305\u62ec(include)\u54ea\u4e9b\u51fd\u6570\u540d\u3002\n    # \u5982\u679c\u662f\u67d0\u4e00\u7c7b\u7684\u51fd\u6570\uff0c\u4f8b\u5982\u7c7bgobang\uff0c\u5219\u53ef\u4ee5\u76f4\u63a5\u5199'gobang.*'\uff0c\u8868\u793a\u4ee5gobang.\u5f00\u5934\u7684\u6240\u6709\u51fd\u6570\u3002\uff08\u5229\u7528\u6b63\u5219\u8868\u8fbe\u5f0f\uff09\u3002\n    config.trace_filter = GlobbingFilter(include=[\n        'infer*',\n        # 'ds_deployer*',\n    ])\n    # \u8be5\u6bb5\u4f5c\u7528\u662f\u5173\u7cfb\u56fe\u4e2d\u4e0d\u5305\u62ec(exclude)\u54ea\u4e9b\u51fd\u6570\u3002(\u6b63\u5219\u8868\u8fbe\u5f0f\u89c4\u5219)\n    # config.trace_filter = GlobbingFilter(exclude=[\n    #     'pycallgraph.*',\n    #     'boto3.*',\n    #     'botocore.*',\n    # ])\n    graphviz = GraphvizOutput()\n    graphviz.output_file = 'callgraph.png'\n    with PyCallGraph(output=graphviz, config=config):\n        result, et = Infer(context, event)\n    return result, et, graphviz.output_file\n",
    "infer.CallTextInfer": "def CallTextInfer(context, event):\n    config = Config()\n    # \u5173\u7cfb\u56fe\u4e2d\u5305\u62ec(include)\u54ea\u4e9b\u51fd\u6570\u540d\u3002\n    # \u5982\u679c\u662f\u67d0\u4e00\u7c7b\u7684\u51fd\u6570\uff0c\u4f8b\u5982\u7c7bgobang\uff0c\u5219\u53ef\u4ee5\u76f4\u63a5\u5199'gobang.*'\uff0c\u8868\u793a\u4ee5gobang.\u5f00\u5934\u7684\u6240\u6709\u51fd\u6570\u3002\uff08\u5229\u7528\u6b63\u5219\u8868\u8fbe\u5f0f\uff09\u3002\n    config.trace_filter = GlobbingFilter(include=[\n        'infer*',\n        # 'ds_deployer*',\n    ])\n\n    text_graphviz = TextGraphvizOutput()\n\n    with PyCallGraph(output=text_graphviz, config=config):\n        result, et = Infer(context, event)\n    return result, et, text_graphviz.output_text\n",
    "infer.Infer": "def Infer(context, event):\n    param = event.body\n    images_minio_info = param['minio_info']\n    images_data_info = param['images_data_info']\n    batch_size = param.get('batch_size', 32)\n    et = ElapsedTime()\n    all_begin = et.ms_timestamp()\n\n    # 1. \u4e0b\u8f7d\u56fe\u7247\u3001\u63a8\u7406\u914d\u7f6e\u3001(\u5fc5\u8981\u65f6\u81ea\u52a8\u52a0\u8f7d\u6a21\u578b)\n    infer_image = InferImage(context, event)\n    \n    time_begin = et.ms_timestamp()\n    is_ok, image_list = infer_image.download_infer_images(images_minio_info, images_data_info)\n    time_end = et.ms_timestamp()\n    et.down_time += (time_end - time_begin)\n\n    if not is_ok:\n        return image_list, et # \u6b64\u5904image_list\u662f\u62a5\u9519\u4fe1\u606f\n    \n    # 2. \u6574\u7406\u6570\u636e\n    infer_json = InferJson(context, event)\n    time_begin = et.ms_timestamp()\n    model_list = infer_json.image_list_to_model_list(image_list)\n    time_end = et.ms_timestamp()\n    et.formal_time += (time_end - time_begin)\n\n    # 3. \u6821\u9a8c\u6570\u636e\n\n    # 4. \u542f\u52a8\u63a8\u7406\n    time_begin = et.ms_timestamp()\n    all_infer_result = {}\n    for model_name, infer_image_list in model_list.items():\n        is_ok, infer_result = one_model_infer_exec(context, event, model_name, infer_image_list, batch_size)\n        if not is_ok:\n            return infer_result, et # \u6b64\u5904infer_result\u662f\u62a5\u9519\u4fe1\u606f\n        all_infer_result[model_name] = infer_result\n    time_end = et.ms_timestamp()\n    et.infer_time += (time_end - time_begin)\n\n    # 5. \u5408\u5e76\u63a8\u7406\u6570\u636e\n    time_begin = et.ms_timestamp()\n    infer_json.merge_result_to_image_list(all_infer_result, image_list)\n    time_end = et.ms_timestamp()\n    et.formal_time += (time_end - time_begin)\n\n    # 6. \u6e05\u7406\u4e34\u65f6\u6570\u636e\n    infer_image.clear_tmp_images_dir()\n    \n    all_end = et.ms_timestamp()\n    et.all_time += (all_end - all_begin)\n    et.image_count = len(image_list)\n\n    return image_list, et\n",
    "infer.one_model_infer_exec": "def one_model_infer_exec(context, event, model_name, infer_image_list, batch_size):\n    model = {\n        'infer_model_name': model_name, \n        'infer_param': {\n            'ok': {'lower_threshold': 0.5, 'upper_threshold': 0.5},\n            'ng': {'lower_threshold': 0.5, 'upper_threshold': 0.5}\n        }\n    }\n    infer_exec = InferExec(context, event)\n    is_ok, infer_result = infer_exec.infer_classifier(model, infer_image_list, batch_size)\n    return is_ok, infer_result\n",
    "infer.Config.__init__": "    def __init__(self, **kwargs):\n        '''\n        You can set defaults in the constructor, e.g. Config(verbose=True)\n        '''\n        self.output = None\n        self.verbose = False\n        self.debug = False\n        self.groups = True\n        self.threaded = False\n        self.memory = False\n\n        # Filtering\n        self.include_stdlib = False\n        self.include_pycallgraph = False\n        self.max_depth = 99999\n\n        self.trace_filter = GlobbingFilter(\n            exclude=['pycallgraph.*'],\n            include=['*'],\n        )\n\n        self.did_init = True\n\n        # Update the defaults with anything from kwargs\n        [setattr(self, k, v) for k, v in kwargs.items()]\n\n        self.create_parser()\n",
    "infer.Config.add_filter_arguments": "    def add_filter_arguments(self):\n        group = self.parser.add_argument_group('filtering')\n        group.add_argument(\n            '-i', '--include', default=[], action='append',\n            help='Wildcard pattern of modules to include in the output. '\n            'You can have multiple include arguments.'\n        )\n\n        group.add_argument(\n            '-e', '--exclude', default=[], action='append',\n            help='Wildcard pattern of modules to exclude in the output. '\n            'You can have multiple exclude arguments.'\n        )\n\n        group.add_argument(\n            '--include-pycallgraph', default=self.include_pycallgraph,\n            action='store_true',\n            help='Do not automatically filter out pycallgraph',\n        )\n\n        group.add_argument(\n            '--max-depth', default=self.max_depth, type=int,\n            help='Maximum stack depth to trace',\n        )\n",
    "infer.Config.add_module_arguments": "    def add_module_arguments(self, usage):\n        subparsers = self.parser.add_subparsers(\n            help='OUTPUT_TYPE', dest='output')\n        parent_parser = self.create_parent_parser()\n\n        for name, cls in list(outputters.items()):\n            cls.add_arguments(subparsers, parent_parser, usage)\n",
    "infer.Config.add_ungrouped_arguments": "    def add_ungrouped_arguments(self):\n        self.parser.add_argument(\n            '-v', '--verbose', action='store_true', default=self.verbose,\n            help='Display informative messages while running')\n\n        self.parser.add_argument(\n            '-d', '--debug', action='store_true', default=self.debug,\n            help='Display debugging messages while running')\n\n        self.parser.add_argument(\n            '-t', '--threaded', action='store_true', default=self.threaded,\n            help='Process traces asyncronously (Experimental)')\n\n        self.parser.add_argument(\n            '-ng', '--no-groups', dest='groups', action='store_false',\n            default=self.groups, help='Do not group functions by module')\n\n        self.parser.add_argument(\n            '-s', '--stdlib', dest='include_stdlib', action='store_true',\n            default=self.include_stdlib,\n            help='Include standard library functions in the trace')\n\n        self.parser.add_argument(\n            '-m', '--memory', action='store_true', default=self.memory,\n            help='(Experimental) Track memory usage')\n",
    "infer.Config.convert_filter_args": "    def convert_filter_args(self):\n        if not self.include:\n            self.include = ['*']\n\n        if not self.include_pycallgraph:\n            self.exclude.append('pycallgraph.*')\n\n        self.trace_filter = GlobbingFilter(\n            include=self.include,\n            exclude=self.exclude,\n        )\n",
    "infer.Config.create_parent_parser": "    def create_parent_parser(self):\n        '''Mixing subparsers with positional arguments can be done with a\n        parents option. Found via: http://stackoverflow.com/a/11109863/11125\n        '''\n        parent_parser = argparse.ArgumentParser(add_help=False)\n        parent_parser.add_argument(\n            'command', metavar='SCRIPT',\n            help='The Python script file to profile',\n        )\n        parent_parser.add_argument(\n            'command_args', metavar='ARG', nargs='*',\n            help='Python script arguments.'\n        )\n        return parent_parser\n",
    "infer.Config.create_parser": "    def create_parser(self):\n        '''Used by the pycallgraph command line interface to parse\n        arguments.\n        '''\n        usage = 'pycallgraph [options] OUTPUT_TYPE [output_options] -- ' \\\n            'SCRIPT.py [ARG ...]'\n\n        self.parser = argparse.ArgumentParser(\n            description='Python Call Graph profiles a Python script and '\n            'generates a call graph visualization.', usage=usage,\n        )\n\n        self.add_ungrouped_arguments()\n        self.add_filter_arguments()\n        self.add_module_arguments(usage)\n",
    "infer.Config.get_output": "    def get_output(self):\n        if not self.output:\n            return\n        output = outputters[self.output]()\n        output.set_config(self)\n        return output\n",
    "infer.Config.log_debug": "    def log_debug(self, text):\n        if self.debug:\n            print(text)\n",
    "infer.Config.log_verbose": "    def log_verbose(self, text):\n        if self.verbose:\n            print(text)\n",
    "infer.Config.parse_args": "    def parse_args(self, args=None):\n        self.parser.parse_args(args, namespace=self)\n        self.convert_filter_args()\n",
    "infer.Config.strip_argv": "    def strip_argv(self):\n        sys.argv = [self.command] + self.command_args\n",
    "infer.ElapsedTime.__init__": "    def __init__(self):\n        self.all_time = 0\n        self.down_time = 0\n        self.formal_time = 0\n        self.infer_time = 0\n        self.image_count = -1\n",
    "infer.ElapsedTime.dump": "    def dump(self):\n        elapsed_time = {'unit': 'ms',\n                        'all_time': self.all_time,\n                        'down_time': self.down_time,\n                        'formal_time': self.formal_time,\n                        'infer_time': self.infer_time,\n                        'image_count': self.image_count,\n                        'image_avg_time': self.all_time // self.image_count\n                        }\n        return json.dumps(elapsed_time, indent=4)\n",
    "infer.ElapsedTime.ms_timestamp": "    def ms_timestamp(self):\n        '''\u6beb\u79d2\u7ea7\u65f6\u95f4\u6233'''\n        return int(round(time.time() * 1000))\n",
    "infer.GlobbingFilter.__call__": "    def __call__(self, full_name=None):\n        for pattern in self.exclude:\n            if fnmatch(full_name, pattern):\n                return False\n\n        for pattern in self.include:\n            if fnmatch(full_name, pattern):\n                return True\n\n        return False\n",
    "infer.GlobbingFilter.__init__": "    def __init__(self, include=None, exclude=None):\n        if include is None and exclude is None:\n            include = ['*']\n            exclude = []\n        elif include is None:\n            include = ['*']\n        elif exclude is None:\n            exclude = []\n\n        self.include = include\n        self.exclude = exclude\n",
    "infer.GraphvizOutput.__init__": "    def __init__(self, **kwargs):\n        self.tool = 'dot'\n        self.output_file = 'pycallgraph.png'\n        self.output_type = 'png'\n        self.font_name = 'Verdana'\n        self.font_size = 7\n        self.group_font_size = 10\n        self.group_border_color = Color(0, 0, 0, 0.8)\n\n        Output.__init__(self, **kwargs)\n\n        self.prepare_graph_attributes()\n",
    "infer.GraphvizOutput.attrs_from_dict": "    def attrs_from_dict(self, d):\n        output = []\n        for attr, val in d.items():\n            output.append('%s = \"%s\"' % (attr, val))\n        return ', '.join(output)\n",
    "infer.GraphvizOutput.debug": "    def debug(self, text):\n        self.processor.config.log_debug(text)\n",
    "infer.GraphvizOutput.done": "    def done(self):\n        source = self.generate()\n\n        self.debug(source)\n\n        fd, temp_name = tempfile.mkstemp()\n        with os.fdopen(fd, 'w') as f:\n            f.write(source)\n\n        cmd = '{} -T{} -o{} {}'.format(\n            self.tool, self.output_type, self.output_file, temp_name\n        )\n\n        self.verbose('Executing: {}'.format(cmd))\n        try:\n            ret = os.system(cmd)\n            if ret:\n                raise PyCallGraphException(\n                    'The command \"%(cmd)s\" failed with error '\n                    'code %(ret)i.' % locals())\n        finally:\n            os.unlink(temp_name)\n\n        self.verbose('Generated {} with {} nodes.'.format(\n            self.output_file, len(self.processor.func_count),\n        ))\n",
    "infer.GraphvizOutput.edge": "    def edge(self, edge, attr):\n        return '\"{0.src_func}\" -> \"{0.dst_func}\" [{1}];'.format(\n            edge, self.attrs_from_dict(attr),\n        )\n",
    "infer.GraphvizOutput.edge_color": "    def edge_color(self, edge):\n        value = float(edge.time.fraction * 2 + edge.calls.fraction) / 3\n        return Color.hsv(value / 2 + .5, value, 0.7)\n",
    "infer.GraphvizOutput.edge_label": "    def edge_label(self, edge):\n        return '{}'.format(edge.calls.value)\n",
    "infer.GraphvizOutput.ensure_binary": "    def ensure_binary(self, cmd):\n        if find_executable(cmd):\n            return\n\n        raise PyCallGraphException(\n            'The command \"{}\" is required to be in your path.'.format(cmd))\n",
    "infer.GraphvizOutput.generate": "    def generate(self):\n        '''Returns a string with the contents of a DOT file for Graphviz to\n        parse.\n        '''\n        indent_join = '\\n' + ' ' * 12\n\n        return textwrap.dedent('''\\\n        digraph G {{\n\n            // Attributes\n            {}\n\n            // Groups\n            {}\n\n            // Nodes\n            {}\n\n            // Edges\n            {}\n\n        }}\n        '''.format(\n            indent_join.join(self.generate_attributes()),\n            indent_join.join(self.generate_groups()),\n            indent_join.join(self.generate_nodes()),\n            indent_join.join(self.generate_edges()),\n        ))\n",
    "infer.GraphvizOutput.generate_attributes": "    def generate_attributes(self):\n        output = []\n        for section, attrs in self.graph_attributes.items():\n            output.append('{} [ {} ];'.format(\n                section, self.attrs_from_dict(attrs),\n            ))\n        return output\n",
    "infer.GraphvizOutput.generate_edges": "    def generate_edges(self):\n        output = []\n\n        for edge in self.processor.edges():\n            attr = {\n                'color': self.edge_color_func(edge).rgba_web(),\n                'label': self.edge_label_func(edge),\n            }\n            output.append(self.edge(edge, attr))\n\n        return output\n",
    "infer.GraphvizOutput.generate_groups": "    def generate_groups(self):\n        if not self.processor.config.groups:\n            return ''\n\n        output = []\n        for group, nodes in self.processor.groups():\n            funcs = [node.name for node in nodes]\n            funcs = '\" \"'.join(funcs)\n            group_color = self.group_border_color.rgba_web()\n            group_font_size = self.group_font_size\n            output.append(\n                'subgraph \"cluster_{group}\" {{ '\n                '\"{funcs}\"; '\n                'label = \"{group}\"; '\n                'fontsize = \"{group_font_size}\"; '\n                'fontcolor = \"black\"; '\n                'style = \"bold\"; '\n                'color=\"{group_color}\"; }}'.format(**locals()))\n        return output\n",
    "infer.GraphvizOutput.generate_nodes": "    def generate_nodes(self):\n        output = []\n        for node in self.processor.nodes():\n            attr = {\n                'color': self.node_color_func(node).rgba_web(),\n                'label': self.node_label_func(node),\n            }\n            output.append(self.node(node.name, attr))\n\n        return output\n",
    "infer.GraphvizOutput.node": "    def node(self, key, attr):\n        return '\"{}\" [{}];'.format(\n            key, self.attrs_from_dict(attr),\n        )\n",
    "infer.GraphvizOutput.node_color": "    def node_color(self, node):\n        value = float(node.time.fraction * 2 + node.calls.fraction) / 3\n        return Color.hsv(value / 2 + .5, value, 0.9)\n",
    "infer.GraphvizOutput.node_label": "    def node_label(self, node):\n        parts = [\n            '{0.name}',\n            'calls: {0.calls.value:n}',\n            'time: {0.time.value:f}s',\n        ]\n\n        if self.processor.config.memory:\n            parts += [\n                'memory in: {0.memory_in.value_human_bibyte}',\n                'memory out: {0.memory_out.value_human_bibyte}',\n            ]\n\n        return r'\\n'.join(parts).format(node)\n",
    "infer.GraphvizOutput.normalize_path": "    def normalize_path(self, path):\n        regex_user_expand = re.compile('\\A~')\n        if regex_user_expand.match(path):\n            path = os.path.expanduser(path)\n        else:\n            path = os.path.expandvars(path)  # expand, just in case\n        return path\n",
    "infer.GraphvizOutput.prepare_graph_attributes": "    def prepare_graph_attributes(self):\n        generated_message = '\\\\n'.join([\n            r'Generated by Python Call Graph v%s' % __version__,\n            r'http://pycallgraph.slowchop.com',\n        ])\n\n        self.graph_attributes = {\n            'graph': {\n                'overlap': 'scalexy',\n                'fontname': self.font_name,\n                'fontsize': self.font_size,\n                'fontcolor': Color(0, 0, 0, 0.5).rgba_web(),\n                'label': generated_message,\n            },\n            'node': {\n                'fontname': self.font_name,\n                'fontsize': self.font_size,\n                'fontcolor': Color(0, 0, 0).rgba_web(),\n                'style': 'filled',\n                'shape': 'rect',\n            },\n            'edge': {\n                'fontname': self.font_name,\n                'fontsize': self.font_size,\n                'fontcolor': Color(0, 0, 0).rgba_web(),\n            }\n        }\n",
    "infer.GraphvizOutput.prepare_output_file": "    def prepare_output_file(self):\n        if self.fp is None:\n            self.output_file = self.normalize_path(self.output_file)\n            self.fp = open(self.output_file, 'wb')\n",
    "infer.GraphvizOutput.reset": "    def reset(self):\n        pass\n",
    "infer.GraphvizOutput.sanity_check": "    def sanity_check(self):\n        self.ensure_binary(self.tool)\n",
    "infer.GraphvizOutput.set_config": "    def set_config(self, config):\n        '''\n        This is a quick hack to move the config variables set in Config into\n        the output module config variables.\n        '''\n        for k, v in config.__dict__.items():\n            if hasattr(self, k) and callable(getattr(self, k)):\n                continue\n            setattr(self, k, v)\n",
    "infer.GraphvizOutput.set_processor": "    def set_processor(self, processor):\n        self.processor = processor\n",
    "infer.GraphvizOutput.should_update": "    def should_update(self):\n        '''Return True if the update method should be called periodically.'''\n        return False\n",
    "infer.GraphvizOutput.start": "    def start(self):\n        '''Initialise variables after initial configuration.'''\n        pass\n",
    "infer.GraphvizOutput.update": "    def update(self):\n        '''Called periodically during a trace, but only when should_update is\n        set to True.\n        '''\n        raise NotImplementedError('update')\n",
    "infer.GraphvizOutput.verbose": "    def verbose(self, text):\n        self.processor.config.log_verbose(text)\n",
    "infer.InferExec.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "infer.InferExec.infer_classifier": "    def infer_classifier(self, model, infer_image_list, batch_size=32):\n        infer_model_name = model['infer_model_name']\n        infer_param = model['infer_param']\n        self.event.info('infer_classifier:model=' + str(model))\n        \n        # \u83b7\u5f97\u6a21\u578b\n        infer_model = InferModel(self.context, self.event)\n        if infer_model.load(infer_model_name, 'ONNX'): # \u9ed8\u8ba4ONNX\uff0c\u9632\u6b62TensorRT\u673a\u578b\u4e0d\u517c\u5bb9\n            model_obj = self.context.models[infer_model_name]\n        else:\n            self.event.info(f'Error: model not exist. {infer_model_name}')\n            return False, {\"msg\": self.event.last_info}\n\n        # \u83b7\u53d6\u5404\u7c7b\u63a8\u7406\u65b9\u6cd5\n        json_info = model_obj['JSON_INFO']\n        # self.event.info('infer_classifier:json_info=' + str(json_info))\n        category, lower_threshold, upper_threshold = self.parse_model_json_info(json_info)\n        self.event.info('infer_classifier:category=' + str(category))\n        result_name = f\"FilterByModel_{infer_model_name}\"\n\n        cfg = list()\n        cfg.append(dict(\n            type=\"FilterByModel\",\n            json_info=json_info,\n            category=category, # [\"OK\", \"NG\"],\n            lower_threshold=lower_threshold, # [0.5, 0.3],\n            upper_threshold=upper_threshold, # [0.5, 0.7],\n            infer_model=model_obj['MODEL'],\n            name=result_name\n            )\n        )\n        # \u521b\u5efa\u63a8\u7406\u7ba1\u9053\n        filter_pipeline = Compose(cfg)\n\n        # \u521b\u5efa\u63a8\u7406\u7684\u6570\u636e\u96c6\n        self.label_threshold_to_array(infer_image_list) # \u5b57\u5178\u8f6c\u5217\u8868\n        self.event.info('infer_classifier:batch_size=' + str(batch_size))\n        dataset = InferDataset(infer_image_list, json_info[\"images_channel\"], batch_size=int(batch_size))\n        eta_iter = ETATimeIter(dataset, [print_info], interval=10, event=self.event)\n\n        try:\n            list_infer_result = []\n            for data in eta_iter:\n                result = filter_pipeline(data)\n                list_infer_result += result[result_name]\n        except:\n            error_msg = traceback.format_exc()\n            if 'len(image_path_list) == len(channels)' in error_msg:\n                error_msg = 'The images do not match the model.'\n            self.event.info(f'Error: model infer fail. {error_msg}')\n            return False, {\"msg\": self.event.last_info}\n\n        return True, list_infer_result\n",
    "infer.InferExec.label_threshold_to_array": "    def label_threshold_to_array(self, infer_image_list):\n        for image_info in infer_image_list.values():\n            image_info['categories'] = list(image_info['label_threshold'].keys())\n            image_info['threshold'] = list(image_info['label_threshold'].values())\n",
    "infer.InferExec.parse_infer_param": "    def parse_infer_param(self, infer_param):\n        category, lower_threshold, upper_threshold = [], [], []\n        for label, threshold in infer_param.items():\n            category.append(label)\n            lower_threshold.append(threshold['lower_threshold'])\n            upper_threshold.append(threshold['upper_threshold'])\n        return category, lower_threshold, upper_threshold\n",
    "infer.InferExec.parse_model_json_info": "    def parse_model_json_info(self, json_info):\n        category = json_info['labels'] # [\"ok\", \"ng\"]\n        lower_threshold = [0.5] * len(category)\n        upper_threshold = [0.5] * len(category)\n        return category, lower_threshold, upper_threshold\n",
    "infer.InferImage.__del__": "    def __del__(self):\n        self.clear_tmp_images_dir()\n",
    "infer.InferImage.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n        self.tmp_images_dir = os.path.join(self.context.TMP_DIR, 'tmp_images/%s' % str(uuid.uuid1()))\n",
    "infer.InferImage.clear_tmp_images_dir": "    def clear_tmp_images_dir(self):\n        if os.path.exists(self.tmp_images_dir):\n            shutil.rmtree(self.tmp_images_dir)\n",
    "infer.InferImage.download_infer_images": "    def download_infer_images(self, minio_info, images_data_info):\n        '''\n        \"images_data_info\": {\n            \"zip\": \"images/Img-none-251.zip\",\n            \"json\": \"images/Img-none-5-model_id.json\"\n        }\n        '''\n        mo = MinioOper(minio_info, self.context, self.event)\n        if not ('zip' in images_data_info.keys() and 'json' in images_data_info.keys()):\n            self.event.info(f'Param Error. images_data_info requires both zip and json fields.')\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u4e0b\u8f7djson\u3001zip\n        local_zip_path = mo.download_file(self.tmp_images_dir, images_data_info['zip'])\n        local_json_path = mo.download_file(self.tmp_images_dir, images_data_info['json'])\n        if local_zip_path == '':\n            self.event.info(f'File download fail: %s' % local_zip_path)\n            return False, {\"msg\": self.event.last_info}\n        if local_json_path == '':\n            self.event.info(f'File download fail: %s' % local_json_path)\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u89e3\u538bzip\n        local_image_dir = local_zip_path.replace('.zip', '')\n        if mo.unzip_file(local_zip_path, local_image_dir):\n            self.event.info(f'local_image_dir: %s' % local_image_dir)\n        else:\n            self.event.info(f'File not found: %s' % local_zip_path)\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u89e3\u6790json\uff0c\u83b7\u53d6\u672c\u5730\u56fe\u7247\u8def\u5f84\u3001\u56fe\u7247\u540d\u79f0\u3001\u53c2\u6570\n        try:\n            with open(local_json_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                self.event.info('Image Json(%s): \\n%s ......' % (images_data_info['json'], content[:300]))\n                image_list = json.loads(content)\n                for image_name, image_info in image_list.items():\n                    for i, path in enumerate(image_info['image_paths']):\n                        image_list[image_name]['image_paths'][i] = os.path.join(local_image_dir, path)\n                    if 'template_paths' in image_info:\n                        for i, path in enumerate(image_info['template_paths']):\n                            image_list[image_name]['template_paths'][i] = os.path.join(local_image_dir, path)\n                    if 'gerber_paths' in image_info:\n                        for i, path in enumerate(image_info['gerber_paths']):\n                            image_list[image_name]['gerber_paths'][i] = os.path.join(local_image_dir, path)\n        except:\n            self.event.info(f'Image Json(%s): Content error.' % images_data_info['json'])\n            traceback.print_exc()\n            return False, {\"msg\": self.event.last_info}\n        return True, image_list\n",
    "infer.InferJson.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "infer.InferJson.get_infer_image": "    def get_infer_image(self, model_name, image_info):\n        infer_image_info = deepcopy(image_info)\n        infer_params = image_info['image_infer_params'][model_name]\n        for key, value in infer_params.items():\n            infer_image_info[key] = deepcopy(value)\n        \n        return infer_image_info\n",
    "infer.InferJson.image_list_to_model_list": "    def image_list_to_model_list(self, image_list):\n        model_list = {}\n        for image_name, image_info in image_list.items():\n            image_infer_params = image_info['image_infer_params']\n            for model_name, model_info in image_infer_params.items():\n                if model_name not in model_list:\n                    model_list[model_name] = {}\n                infer_image_info = self.get_infer_image(model_name, image_info)\n                model_list[model_name][image_name] = infer_image_info\n        \n        return model_list\n",
    "infer.InferJson.merge_result_to_image_list": "    def merge_result_to_image_list(self, all_infer_result, image_list):\n        # \u63a8\u7406\u7ed3\u679c\u5408\u5e76\n        for model_name, result_list in all_infer_result.items():\n            for result in result_list:\n                image_name = result['image_name']\n                image_list[image_name]['image_infer_params'][model_name]['infer_result'] = deepcopy(result['labels'])\n        \n        # \u56fe\u7247\u8def\u5f84\u7b80\u5316\n        for image_info in image_list.values():\n            for i, path in enumerate(image_info['image_paths']):\n                image_info['image_paths'][i] = os.path.basename(path)\n",
    "infer.PyCallGraph.__enter__": "    def __enter__(self):\n        self.start()\n",
    "infer.PyCallGraph.__exit__": "    def __exit__(self, type, value, traceback):\n        self.done()\n",
    "infer.PyCallGraph.__init__": "    def __init__(self, output=None, config=None):\n        '''output can be a single Output instance or an iterable with many\n        of them.  Example usage:\n\n            PyCallGraph(config=Config(), output=GraphvizOutput())\n        '''\n        locale.setlocale(locale.LC_ALL, '')\n\n        if output is None:\n            self.output = []\n        elif isinstance(output, Output):\n            self.output = [output]\n        else:\n            self.output = output\n\n        self.config = config or Config()\n\n        configured_ouput = self.config.get_output()\n        if configured_ouput:\n            self.output.append(configured_ouput)\n\n        self.reset()\n",
    "infer.PyCallGraph.add_output": "    def add_output(self, output):\n        self.output.append(output)\n        self.prepare_output(output)\n",
    "infer.PyCallGraph.done": "    def done(self):\n        '''Stops the trace and tells the outputters to generate their\n        output.\n        '''\n        self.stop()\n\n        self.generate()\n",
    "infer.PyCallGraph.generate": "    def generate(self):\n        # If in threaded mode, wait for the processor thread to complete\n        self.tracer.done()\n\n        for output in self.output:\n            output.done()\n",
    "infer.PyCallGraph.get_tracer_class": "    def get_tracer_class(self):\n        if self.config.threaded:\n            return AsyncronousTracer\n        else:\n            return SyncronousTracer\n",
    "infer.PyCallGraph.prepare_output": "    def prepare_output(self, output):\n        output.sanity_check()\n        output.set_processor(self.tracer.processor)\n        output.reset()\n",
    "infer.PyCallGraph.reset": "    def reset(self):\n        '''Resets all collected statistics.  This is run automatically by\n        start(reset=True) and when the class is initialized.\n        '''\n        self.tracer = self.get_tracer_class()(self.output, config=self.config)\n\n        for output in self.output:\n            self.prepare_output(output)\n",
    "infer.PyCallGraph.start": "    def start(self, reset=True):\n        '''Begins a trace.  Setting reset to True will reset all previously\n        recorded trace data.\n        '''\n        if not self.output:\n            raise PyCallGraphException(\n                'No outputs declared. Please see the '\n                'examples in the online documentation.'\n            )\n\n        if reset:\n            self.reset()\n\n        for output in self.output:\n            output.start()\n\n        self.tracer.start()\n",
    "infer.PyCallGraph.stop": "    def stop(self):\n        '''Stops the currently running trace, if any.'''\n        self.tracer.stop()\n",
    "infer.TextGraphvizOutput.__init__": "    def __init__(self, **kwargs):\n        self.tool = 'dot'\n        self.output_file = 'pycallgraph.png'\n        self.output_type = 'png'\n        self.font_name = 'Verdana'\n        self.font_size = 7\n        self.group_font_size = 10\n        self.group_border_color = Color(0, 0, 0, 0.8)\n\n        Output.__init__(self, **kwargs)\n\n        self.prepare_graph_attributes()\n",
    "infer.TextGraphvizOutput.attrs_from_dict": "    def attrs_from_dict(self, d):\n        output = []\n        for attr, val in d.items():\n            output.append('%s = \"%s\"' % (attr, val))\n        return ', '.join(output)\n",
    "infer.TextGraphvizOutput.debug": "    def debug(self, text):\n        self.processor.config.log_debug(text)\n",
    "infer.TextGraphvizOutput.done": "        def done(self):\n            source = self.generate()\n            # print(source)\n            self.output_text = source\n",
    "infer.TextGraphvizOutput.edge": "    def edge(self, edge, attr):\n        return '\"{0.src_func}\" -> \"{0.dst_func}\" [{1}];'.format(\n            edge, self.attrs_from_dict(attr),\n        )\n",
    "infer.TextGraphvizOutput.edge_color": "    def edge_color(self, edge):\n        value = float(edge.time.fraction * 2 + edge.calls.fraction) / 3\n        return Color.hsv(value / 2 + .5, value, 0.7)\n",
    "infer.TextGraphvizOutput.edge_label": "    def edge_label(self, edge):\n        return '{}'.format(edge.calls.value)\n",
    "infer.TextGraphvizOutput.ensure_binary": "    def ensure_binary(self, cmd):\n        if find_executable(cmd):\n            return\n\n        raise PyCallGraphException(\n            'The command \"{}\" is required to be in your path.'.format(cmd))\n",
    "infer.TextGraphvizOutput.generate": "    def generate(self):\n        '''Returns a string with the contents of a DOT file for Graphviz to\n        parse.\n        '''\n        indent_join = '\\n' + ' ' * 12\n\n        return textwrap.dedent('''\\\n        digraph G {{\n\n            // Attributes\n            {}\n\n            // Groups\n            {}\n\n            // Nodes\n            {}\n\n            // Edges\n            {}\n\n        }}\n        '''.format(\n            indent_join.join(self.generate_attributes()),\n            indent_join.join(self.generate_groups()),\n            indent_join.join(self.generate_nodes()),\n            indent_join.join(self.generate_edges()),\n        ))\n",
    "infer.TextGraphvizOutput.generate_attributes": "    def generate_attributes(self):\n        output = []\n        for section, attrs in self.graph_attributes.items():\n            output.append('{} [ {} ];'.format(\n                section, self.attrs_from_dict(attrs),\n            ))\n        return output\n",
    "infer.TextGraphvizOutput.generate_edges": "    def generate_edges(self):\n        output = []\n\n        for edge in self.processor.edges():\n            attr = {\n                'color': self.edge_color_func(edge).rgba_web(),\n                'label': self.edge_label_func(edge),\n            }\n            output.append(self.edge(edge, attr))\n\n        return output\n",
    "infer.TextGraphvizOutput.generate_groups": "    def generate_groups(self):\n        if not self.processor.config.groups:\n            return ''\n\n        output = []\n        for group, nodes in self.processor.groups():\n            funcs = [node.name for node in nodes]\n            funcs = '\" \"'.join(funcs)\n            group_color = self.group_border_color.rgba_web()\n            group_font_size = self.group_font_size\n            output.append(\n                'subgraph \"cluster_{group}\" {{ '\n                '\"{funcs}\"; '\n                'label = \"{group}\"; '\n                'fontsize = \"{group_font_size}\"; '\n                'fontcolor = \"black\"; '\n                'style = \"bold\"; '\n                'color=\"{group_color}\"; }}'.format(**locals()))\n        return output\n",
    "infer.TextGraphvizOutput.generate_nodes": "    def generate_nodes(self):\n        output = []\n        for node in self.processor.nodes():\n            attr = {\n                'color': self.node_color_func(node).rgba_web(),\n                'label': self.node_label_func(node),\n            }\n            output.append(self.node(node.name, attr))\n\n        return output\n",
    "infer.TextGraphvizOutput.node": "    def node(self, key, attr):\n        return '\"{}\" [{}];'.format(\n            key, self.attrs_from_dict(attr),\n        )\n",
    "infer.TextGraphvizOutput.node_color": "    def node_color(self, node):\n        value = float(node.time.fraction * 2 + node.calls.fraction) / 3\n        return Color.hsv(value / 2 + .5, value, 0.9)\n",
    "infer.TextGraphvizOutput.node_label": "    def node_label(self, node):\n        parts = [\n            '{0.name}',\n            'calls: {0.calls.value:n}',\n            'time: {0.time.value:f}s',\n        ]\n\n        if self.processor.config.memory:\n            parts += [\n                'memory in: {0.memory_in.value_human_bibyte}',\n                'memory out: {0.memory_out.value_human_bibyte}',\n            ]\n\n        return r'\\n'.join(parts).format(node)\n",
    "infer.TextGraphvizOutput.normalize_path": "    def normalize_path(self, path):\n        regex_user_expand = re.compile('\\A~')\n        if regex_user_expand.match(path):\n            path = os.path.expanduser(path)\n        else:\n            path = os.path.expandvars(path)  # expand, just in case\n        return path\n",
    "infer.TextGraphvizOutput.prepare_graph_attributes": "    def prepare_graph_attributes(self):\n        generated_message = '\\\\n'.join([\n            r'Generated by Python Call Graph v%s' % __version__,\n            r'http://pycallgraph.slowchop.com',\n        ])\n\n        self.graph_attributes = {\n            'graph': {\n                'overlap': 'scalexy',\n                'fontname': self.font_name,\n                'fontsize': self.font_size,\n                'fontcolor': Color(0, 0, 0, 0.5).rgba_web(),\n                'label': generated_message,\n            },\n            'node': {\n                'fontname': self.font_name,\n                'fontsize': self.font_size,\n                'fontcolor': Color(0, 0, 0).rgba_web(),\n                'style': 'filled',\n                'shape': 'rect',\n            },\n            'edge': {\n                'fontname': self.font_name,\n                'fontsize': self.font_size,\n                'fontcolor': Color(0, 0, 0).rgba_web(),\n            }\n        }\n",
    "infer.TextGraphvizOutput.prepare_output_file": "    def prepare_output_file(self):\n        if self.fp is None:\n            self.output_file = self.normalize_path(self.output_file)\n            self.fp = open(self.output_file, 'wb')\n",
    "infer.TextGraphvizOutput.reset": "    def reset(self):\n        pass\n",
    "infer.TextGraphvizOutput.sanity_check": "    def sanity_check(self):\n        self.ensure_binary(self.tool)\n",
    "infer.TextGraphvizOutput.set_config": "    def set_config(self, config):\n        '''\n        This is a quick hack to move the config variables set in Config into\n        the output module config variables.\n        '''\n        for k, v in config.__dict__.items():\n            if hasattr(self, k) and callable(getattr(self, k)):\n                continue\n            setattr(self, k, v)\n",
    "infer.TextGraphvizOutput.set_processor": "    def set_processor(self, processor):\n        self.processor = processor\n",
    "infer.TextGraphvizOutput.should_update": "    def should_update(self):\n        '''Return True if the update method should be called periodically.'''\n        return False\n",
    "infer.TextGraphvizOutput.start": "    def start(self):\n        '''Initialise variables after initial configuration.'''\n        pass\n",
    "infer.TextGraphvizOutput.update": "    def update(self):\n        '''Called periodically during a trace, but only when should_update is\n        set to True.\n        '''\n        raise NotImplementedError('update')\n",
    "infer.TextGraphvizOutput.verbose": "    def verbose(self, text):\n        self.processor.config.log_verbose(text)\n",
    "infer_context.InferContext.__init__": "    def __init__(self):\n        self.models = {}\n        self.minio_info = {\n            \"bucket\": os.getenv('INFER_MINIO_bucket', 'infer'),\n            \"access_key_id\": os.getenv('INFER_MINIO_access_key_id', 'deepsight'),\n            \"secret_key\": os.getenv('INFER_MINIO_secret_key', 'deepsight'),\n            \"endpoint_url\": os.getenv('INFER_MINIO_endpoint_url', 'http://172.29.10.42:9001/')\n        }\n        self.WORKSPACE = './'\n        self.MODELS_DIR = os.path.join(self.WORKSPACE, 'models_dir')\n        self.TMP_DIR = os.path.join(self.WORKSPACE, 'tmp')\n",
    "infer_context.InferContext.delete_model": "    def delete_model(self, model_name):\n        if model_name in self.models:\n            # \u5220\u9664\u5185\u5b58\u4e2d\u6570\u636e\n            self.models.pop(model_name)\n        \n        one_model_dir = os.path.join(self.MODELS_DIR, model_name)\n        if os.path.exists(one_model_dir):\n            # \u5220\u9664\u78c1\u76d8\u4e2d\u6587\u4ef6\n            shutil.rmtree(one_model_dir)\n\n        return True\n",
    "infer_context.InferContext.get_model_list": "    def get_model_list(self):\n        return list(self.models.keys())\n",
    "infer_event.InferEvent.__init__": "    def __init__(self, body={}, path='/classifier-many-model', method='POST', job_id=''):\n        self.body = body\n        self.path = path\n        self.method = method\n        self.post_log = PostLog(job_id)\n\n        self.last_info = ''\n",
    "infer_event.InferEvent.info": "    def info(self, log_text):\n        self.last_info = log_text\n        self.post_log('INFO', log_text)\n",
    "infer_event.InferEvent.test_init": "    def test_init(self):\n        data = [\n            {\n                'infer_model_name': 'classification_cls_test_test_m_2023-03-31-02-35-27',\n                'infer_param': {\n                    'OK': {'lower_threshold': 0.5, 'upper_threshold': 0.5},\n                    'NG': {'lower_threshold': 0.5, 'upper_threshold': 0.5}\n                },\n                'minio_info': {\n                    'bucket': 'infer',\n                    'access_key_id': 'minio',\n                    'secret_key': 'deepsight',\n                    'endpoint_url': 'http://172.29.10.135:9001/'\n                },\n                'data_info': {\n                    \"59e248ec-ddb7-11ed-b21f-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 1}\n                    },\n                    \"59e248ed-ddb7-11ed-9782-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 0}\n                    },\n                    \"59e248ee-ddb7-11ed-9ae6-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 0}\n                    },\n                    \"59e248ef-ddb7-11ed-81a4-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 1}\n                    },\n                    \"59e248f0-ddb7-11ed-b0e9-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0.5, \"NG\": 0.5}\n                    }\n                }\n            },\n            {\n                'infer_model_name': 'classification_cls_test_test_m_2023-04-04-08-14-48',\n                'infer_param': {\n                    'OK': {'lower_threshold': 0.5, 'upper_threshold': 0.5},\n                    'NG': {'lower_threshold': 0.5, 'upper_threshold': 0.5}\n                },\n                'minio_info': {\n                    'bucket': 'infer',\n                    'access_key_id': 'minio',\n                    'secret_key': 'deepsight',\n                    'endpoint_url': 'http://172.29.10.135:9001/'\n                },\n                'image_base_dir': '',\n                'image_list': {\n                    \"59e248ec-ddb7-11ed-b21f-34735ac51bd8\": {\n                        \"image_zip_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 1}\n                    },\n                    \"59e248ed-ddb7-11ed-9782-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 0}\n                    },\n                    \"59e248ee-ddb7-11ed-9ae6-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 0}\n                    },\n                    \"59e248ef-ddb7-11ed-81a4-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 1}\n                    },\n                    \"59e248f0-ddb7-11ed-b0e9-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0.5, \"NG\": 0.5}\n                    }\n                }\n            }\n        ]\n\n        self.body = data\n        self.path = '/classifier-many-model'\n        self.method = 'POST'\n",
    "infer_event.PostLog.__call__": "    def __call__(self, level, msg):\n        # if level == 'INFO':\n        #     return\n        if level == 'DEBUG':\n            self.logger.debug(msg)\n        if level == 'INFO':\n            self.logger.info(msg)\n        if level == 'WARNING':\n            self.logger.warning(msg)\n        if level == 'ERROR':\n            self.logger.error(msg)\n        if level == 'CRITICAL':\n            self.logger.critical(msg)\n\n        if self.job_id != '' and level in ['ERROR', 'WARNING', 'CRITICAL']:\n            self.post_log(msg, self.job_id, level)\n",
    "infer_event.PostLog.__init__": "    def __init__(self, job_id):\n        print('PostLog init, job_id=', job_id)\n        self.job_id = job_id\n        self.logger = S_LOGGER\n",
    "infer_event.PostLog.post_log": "    def post_log(self, msg, job_id, level=\"INFO\"):\n        # print(msg)\n        url = f'{JOB_HOST}/api/log/'\n        data = {\n            \"level\": 'INFO',\n            \"log_text\": '> ' + msg,\n            \"job\": job_id\n        }\n        if level != 'ERROR':\n            data['level'] = level\n            requests.post(url, data=data)\n        else:\n            requests.post(url, data=data)\n            data['level'] = 'ERROR'\n            data['log_text'] = \"-\" * 40 + \"infer ERROR end\" + \"-\" * 40\n            requests.post(url, data=data)\n",
    "infer_exec.load_json": "def load_json(json_path):\n    try:\n        with open(json_path, \"r\", encoding=\"utf-8\") as fp:\n            json_data = orjson.loads(fp.read())\n    except:\n        json_data = {}\n    return json_data\n",
    "infer_exec.ls_folder": "def ls_folder(folder, postfix=None, use_sort=True):\n    \"\"\"\n    \u5217\u51fa\u8f93\u5165folder\u4e0b\u9762\u7684\u6240\u6709\u6587\u4ef6\u76ee\u5f55\n    \"\"\"\n    os_sorted = natsort.os_sorted if use_sort else lambda x, *args, **kwargs: x\n    if os.path.exists(folder):\n        if postfix is None:\n            return os_sorted([os.path.join(folder, f) for f in os.listdir(folder)])\n        else:\n            if isinstance(postfix, str):\n                postfix = [postfix.upper()]\n            else:\n                postfix = [p.upper() for p in postfix]\n            return os_sorted([os.path.join(folder, f) for f in os.listdir(folder) if f[f.rfind(\".\")+1:].upper() in postfix])\n    else:\n        return []\n",
    "infer_exec.print_info": "def print_info(self: ETATimeIter, event):\n    if (self.count + 1) % self.interval == 0:\n        info_text = f\"=> process {self.count + 1}/{self.total_count}: ETA:{self.eta_time}\"\n        print(\"INFO\", info_text)\n        event.info(info_text)\n",
    "infer_exec.Compose.__call__": "    def __call__(self, data: dict):\n        \"\"\"\u8c03\u7528\u51fd\u6570\u4ee5\u6309\u987a\u5e8f\u5e94\u7528\u56fe\u50cf\u589e\u5f3a\u53d8\u6362.\n        \u53c2\u6570:\n            data (dict): \u9700\u8981\u8f93\u5165\u7684\u6570\u636e.\n        Returns:\n           dict: \u5e8f\u5217\u5e94\u7528\u540e\u7684\u5b57\u5178\u683c\u5f0f.\n        \"\"\"\n        for t in self.modules:\n            data = t(**data)\n            if data is None:\n                return None\n        return data\n",
    "infer_exec.Compose.__init__": "    def __init__(self, modules):\n        \"\"\"\n        \u987a\u5e8f\u6267\u884c\u7684\u6a21\u578b\u6a21\u7ec4\u7ba1\u9053\u6d41\u3002\n        \u53c2\u6570:\n            modules (Sequence[dict | callable])\uff1a\u987a\u5e8f\u6267\u884c\u7684\u6a21\u7ec4\n        \"\"\"\n        self.modules = []\n        for module in modules:\n            if isinstance(module, dict):\n                module = build_module(module)\n                self.modules.append(module)\n            elif callable(module):\n                self.modules.append(module)\n            else:\n                raise TypeError('modules \u5fc5\u987b\u662f\u4e00\u4e2a\u53ef\u4ee5\u88ab\u8c03\u7528\u7684\u5bf9\u8c61\u6216\u8005\u662f\u4e00\u4e2a\u5b57\u5178')\n",
    "infer_exec.ETATimeIter.__init__": "    def __init__(self, iterable, callback_func_before_iter=[], callback_func_after_iter=[], event=None, **kwargs):\n        self.event = event\n        self.count = 0\n        self.used_time =0\n        self.t = 0\n        self.total_count = len(iterable)\n        self.iterable = iterable\n        self.callback_func_before_iter = callback_func_before_iter\n        self.callback_func_after_iter = callback_func_after_iter\n\n        # \u5982\u82e5\u4e0d\u5b58\u5728\u56de\u8c03\u51fd\u6570\uff0c\u5219\u4e0d\u6267\u884c\u8ba1\u65f6\n        self.enable = len(callback_func_before_iter) or len(callback_func_after_iter)\n        # \u6dfb\u52a0\u5176\u4f59\u53c2\u6570,\u5171\u56de\u8c03\u51fd\u6570\u4f7f\u7528\n        self._add_attr(**kwargs)\n",
    "infer_exec.ETATimeIter.__iter__": "    def __iter__(self):\n        if self.enable:\n            self._init_time()\n            for obj in self.iterable:\n                self.before_iter()\n                yield obj\n                self._update_time()\n                self.after_iter()\n        else:\n            for obj in self.iterable:\n                yield obj\n",
    "infer_exec.ETATimeIter.__len__": "    def __len__(self):\n        return len(self.iterable)\n",
    "infer_exec.ETATimeIter._add_attr": "    def _add_attr(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n",
    "infer_exec.ETATimeIter._init_time": "    def _init_time(self):\n        self.t = time.time()\n",
    "infer_exec.ETATimeIter._update_time": "    def _update_time(self):\n        step_time = time.time()-self.t\n        self.t = time.time()\n        self.count += 1\n        self.used_time += step_time\n",
    "infer_exec.ETATimeIter.after_iter": "    def after_iter(self):\n        for func in self.callback_func_after_iter:\n            func(self)\n",
    "infer_exec.ETATimeIter.before_iter": "    def before_iter(self):\n        for func in self.callback_func_before_iter:\n            func(self, self.event)\n",
    "infer_exec.InferDataset.__getitem__": "    def __getitem__(self, index):\n        image_name = self.image_names[index]\n        image_info = self.image_list[index]\n\n        detail_infos = image_info.get(\"detail_infos\", [])\n        image_paths = image_info[\"image_paths\"] + image_info.get(\"template_paths\", []) + image_info.get(\"gerber_paths\", [])\n        threshold = image_info.get(\"threshold\", None)\n        categories = image_info.get(\"categories\", None)\n        area = image_info.get(\"area\", None)\n        area_rule = image_info.get(\"area_rule\", None)   # [lower, upper]\n\n        images = read_images(image_paths, channels=self.image_channels)\n        return dict(image_name=image_name, images=images, image_paths=image_paths, threshold=threshold,\n                    categories=categories, detail_infos=detail_infos, area=area, area_rule=area_rule)\n",
    "infer_exec.InferDataset.__init__": "    def __init__(self, images_data_info, image_channels, batch_size=32, **kwargs):\n        self.images_data_info = images_data_info\n        self.batch_size = batch_size\n        self.image_names = []\n        self.image_list = []\n        self.image_channels = image_channels\n        self.load_data()\n",
    "infer_exec.InferDataset.__iter__": "    def __iter__(self):\n        data_list = []\n        for i in range(len(self.image_list)):\n            if i % self.batch_size == 0 and i != 0:\n                yield self.collect_data(data_list)\n                data_list = []\n            data = self[i]\n            data_list.append(data)\n        yield self.collect_data(data_list)\n",
    "infer_exec.InferDataset.__len__": "    def __len__(self):\n        return len(self.image_list) // self.batch_size + 1 if len(self.image_list) % self.batch_size != 0 else \\\n            len(self.image_list) // self.batch_size\n",
    "infer_exec.InferDataset.collect_data": "    @staticmethod\n    def collect_data(data_list: List[Dict]) -> Dict:\n        if len(data_list) == 0:\n            raise StopIteration\n        keys = list(data_list[0].keys())\n        data_info = dict()\n        for key in keys:\n            data_info[key] = [d.get(key)for d in data_list]\n        return data_info\n",
    "infer_exec.InferDataset.load_data": "    def load_data(self):\n        for img_name, img_info in self.images_data_info.items():\n            self.image_names.append(img_name)\n            self.image_list.append(img_info)\n",
    "infer_exec.InferExec.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "infer_exec.InferExec.infer_classifier": "    def infer_classifier(self, model, infer_image_list, batch_size=32):\n        infer_model_name = model['infer_model_name']\n        infer_param = model['infer_param']\n        self.event.info('infer_classifier:model=' + str(model))\n        \n        # \u83b7\u5f97\u6a21\u578b\n        infer_model = InferModel(self.context, self.event)\n        if infer_model.load(infer_model_name, 'ONNX'): # \u9ed8\u8ba4ONNX\uff0c\u9632\u6b62TensorRT\u673a\u578b\u4e0d\u517c\u5bb9\n            model_obj = self.context.models[infer_model_name]\n        else:\n            self.event.info(f'Error: model not exist. {infer_model_name}')\n            return False, {\"msg\": self.event.last_info}\n\n        # \u83b7\u53d6\u5404\u7c7b\u63a8\u7406\u65b9\u6cd5\n        json_info = model_obj['JSON_INFO']\n        # self.event.info('infer_classifier:json_info=' + str(json_info))\n        category, lower_threshold, upper_threshold = self.parse_model_json_info(json_info)\n        self.event.info('infer_classifier:category=' + str(category))\n        result_name = f\"FilterByModel_{infer_model_name}\"\n\n        cfg = list()\n        cfg.append(dict(\n            type=\"FilterByModel\",\n            json_info=json_info,\n            category=category, # [\"OK\", \"NG\"],\n            lower_threshold=lower_threshold, # [0.5, 0.3],\n            upper_threshold=upper_threshold, # [0.5, 0.7],\n            infer_model=model_obj['MODEL'],\n            name=result_name\n            )\n        )\n        # \u521b\u5efa\u63a8\u7406\u7ba1\u9053\n        filter_pipeline = Compose(cfg)\n\n        # \u521b\u5efa\u63a8\u7406\u7684\u6570\u636e\u96c6\n        self.label_threshold_to_array(infer_image_list) # \u5b57\u5178\u8f6c\u5217\u8868\n        self.event.info('infer_classifier:batch_size=' + str(batch_size))\n        dataset = InferDataset(infer_image_list, json_info[\"images_channel\"], batch_size=int(batch_size))\n        eta_iter = ETATimeIter(dataset, [print_info], interval=10, event=self.event)\n\n        try:\n            list_infer_result = []\n            for data in eta_iter:\n                result = filter_pipeline(data)\n                list_infer_result += result[result_name]\n        except:\n            error_msg = traceback.format_exc()\n            if 'len(image_path_list) == len(channels)' in error_msg:\n                error_msg = 'The images do not match the model.'\n            self.event.info(f'Error: model infer fail. {error_msg}')\n            return False, {\"msg\": self.event.last_info}\n\n        return True, list_infer_result\n",
    "infer_exec.InferExec.label_threshold_to_array": "    def label_threshold_to_array(self, infer_image_list):\n        for image_info in infer_image_list.values():\n            image_info['categories'] = list(image_info['label_threshold'].keys())\n            image_info['threshold'] = list(image_info['label_threshold'].values())\n",
    "infer_exec.InferExec.parse_infer_param": "    def parse_infer_param(self, infer_param):\n        category, lower_threshold, upper_threshold = [], [], []\n        for label, threshold in infer_param.items():\n            category.append(label)\n            lower_threshold.append(threshold['lower_threshold'])\n            upper_threshold.append(threshold['upper_threshold'])\n        return category, lower_threshold, upper_threshold\n",
    "infer_exec.InferExec.parse_model_json_info": "    def parse_model_json_info(self, json_info):\n        category = json_info['labels'] # [\"ok\", \"ng\"]\n        lower_threshold = [0.5] * len(category)\n        upper_threshold = [0.5] * len(category)\n        return category, lower_threshold, upper_threshold\n",
    "infer_exec.InferModel.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "infer_exec.InferModel.get_model_obj": "    def get_model_obj(self, oi_path, type='ONNX'):\n        print(f'Load type: {type}')\n        if type == 'TensorRT':\n            model = TRTInfer(oi_path)\n            # TRT\u8f6c\u5316\u7ed3\u679c\u4e0a\u4f20\u5230minio\n            if model.have_new_file:\n                self.upload_load_model_zip(oi_path)\n\n            return model\n        elif type == 'ONNX':\n            onnx_model = OnnxInfer(oi_path)\n            return onnx_model\n        else:\n            return None\n",
    "infer_exec.InferModel.init_context_model": "    def init_context_model(self, local_models_dir, minio_info, minio_model_filepath, type):\n        # 1. \u4e0b\u8f7d\u6a21\u578b\u6587\u4ef6\n        self.mo = MinioOper(minio_info, self.context, self.event)\n        ret, engine_folder = self.mo.download_model_file(local_models_dir, minio_model_filepath) # \u4e0b\u8f7dzip\uff0c\u89e3\u538b\u5230\u5f53\u524d\u6587\u4ef6\u5939\uff0c\u5220\u9664zip\n        if not ret:\n            return False # \u4e0b\u8f7d\u5931\u8d25\n\n        model_name = os.path.basename(engine_folder)\n        self.event.info(f'Model init Begin...  (model_name={model_name})')\n        \n        # 2. \u83b7\u53d6json\u6587\u4ef6\u5e76\u63d0\u53d6\u76f8\u5173\u4fe1\u606f\n        json_path = ls_folder(engine_folder, \"json\")[0]\n        oi_path = ls_folder(engine_folder, \"oi\")[0]\n        json_info = load_json(json_path)\n        label_2_class = {i:label for i, label in enumerate(json_info[\"labels\"])}\n\n        # 3. \u83b7\u53d6\u7f51\u7edc\u6a21\u578b\u6587\u4ef6\u5e76\u521b\u5efa\u6a21\u578b\n        if type not in ['TensorRT', 'ONNX']:\n            type = 'ONNX'\n        model = self.get_model_obj(oi_path, type)\n\n        # 4. \u6d89\u53ca\u63a8\u7406\u7684\u6570\u636e\u52a0\u8f7d\u5230context\n        self.context.models[model_name] = {\n            'MODEL': model,\n            'LABEL_2_CLASS': label_2_class, # {0: 'NG', 1: 'OK'}\n            'THRESHOLD': json_info[\"threshold\"],\n            'JSON_INFO': json_info\n        }\n        \n        self.event.info(f'Model init Success! model_name={model_name}')\n        return True\n",
    "infer_exec.InferModel.load": "    def load(self, model_name, type='ONNX'):\n        if model_name in self.context.models.keys():\n            return True\n        return self.init_context_model(self.context.MODELS_DIR, self.context.minio_info, f\"/models/{model_name}.zip\", type)\n",
    "infer_exec.InferModel.upload_load_model_zip": "    def upload_load_model_zip(self, oi_path):\n        src_dir = os.path.dirname(oi_path)\n        zip_path = src_dir + '.zip'\n        self.mo.zip_folder(src_dir, zip_path)\n\n        src_minio_path = 'models/{}'.format(os.path.basename(zip_path))\n        dst_minio_path = 'models_backup/{}'.format(os.path.basename(zip_path))\n        self.mo.move_file(src_minio_path, dst_minio_path)\n\n        self.mo.upload_file(zip_path, 'models')\n",
    "infer_exec.OnnxInfer.__call__": "    def __call__(self, input_ts: list):\n        input_info = {name.name: data for name, data in zip(self.session.get_inputs(), input_ts)}\n        onnx_results = self.session.run([], input_info)\n        return onnx_results\n",
    "infer_exec.OnnxInfer.__init__": "    def __init__(self, oi_file: str):\n        providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n\n        onnx_file = oi_file.replace(\".oi\", \".onnx\")\n        if os.path.exists(onnx_file):\n            self.session = onnxruntime.InferenceSession(onnx_file, providers=providers)\n            # self.session.set_providers(['CUDAExecutionProvider'], [ {'device_id': 0}]) # ONNX runtime\u6307\u5b9aGPU\n        elif os.path.exists(oi_file):\n            encrypt_file1_to_file2(oi_file, onnx_file, is_reverse=True)\n            self.session = onnxruntime.InferenceSession(onnx_file, providers=providers)\n            # self.session.set_providers(['CUDAExecutionProvider'], [ {'device_id': 0}]) # ONNX runtime\u6307\u5b9aGPU\n        else:\n            raise ValueError(f\"Can not file oi file and onnx file:{onnx_file}\")\n",
    "infer_image.InferImage.__del__": "    def __del__(self):\n        self.clear_tmp_images_dir()\n",
    "infer_image.InferImage.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n        self.tmp_images_dir = os.path.join(self.context.TMP_DIR, 'tmp_images/%s' % str(uuid.uuid1()))\n",
    "infer_image.InferImage.clear_tmp_images_dir": "    def clear_tmp_images_dir(self):\n        if os.path.exists(self.tmp_images_dir):\n            shutil.rmtree(self.tmp_images_dir)\n",
    "infer_image.InferImage.download_infer_images": "    def download_infer_images(self, minio_info, images_data_info):\n        '''\n        \"images_data_info\": {\n            \"zip\": \"images/Img-none-251.zip\",\n            \"json\": \"images/Img-none-5-model_id.json\"\n        }\n        '''\n        mo = MinioOper(minio_info, self.context, self.event)\n        if not ('zip' in images_data_info.keys() and 'json' in images_data_info.keys()):\n            self.event.info(f'Param Error. images_data_info requires both zip and json fields.')\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u4e0b\u8f7djson\u3001zip\n        local_zip_path = mo.download_file(self.tmp_images_dir, images_data_info['zip'])\n        local_json_path = mo.download_file(self.tmp_images_dir, images_data_info['json'])\n        if local_zip_path == '':\n            self.event.info(f'File download fail: %s' % local_zip_path)\n            return False, {\"msg\": self.event.last_info}\n        if local_json_path == '':\n            self.event.info(f'File download fail: %s' % local_json_path)\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u89e3\u538bzip\n        local_image_dir = local_zip_path.replace('.zip', '')\n        if mo.unzip_file(local_zip_path, local_image_dir):\n            self.event.info(f'local_image_dir: %s' % local_image_dir)\n        else:\n            self.event.info(f'File not found: %s' % local_zip_path)\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u89e3\u6790json\uff0c\u83b7\u53d6\u672c\u5730\u56fe\u7247\u8def\u5f84\u3001\u56fe\u7247\u540d\u79f0\u3001\u53c2\u6570\n        try:\n            with open(local_json_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                self.event.info('Image Json(%s): \\n%s ......' % (images_data_info['json'], content[:300]))\n                image_list = json.loads(content)\n                for image_name, image_info in image_list.items():\n                    for i, path in enumerate(image_info['image_paths']):\n                        image_list[image_name]['image_paths'][i] = os.path.join(local_image_dir, path)\n                    if 'template_paths' in image_info:\n                        for i, path in enumerate(image_info['template_paths']):\n                            image_list[image_name]['template_paths'][i] = os.path.join(local_image_dir, path)\n                    if 'gerber_paths' in image_info:\n                        for i, path in enumerate(image_info['gerber_paths']):\n                            image_list[image_name]['gerber_paths'][i] = os.path.join(local_image_dir, path)\n        except:\n            self.event.info(f'Image Json(%s): Content error.' % images_data_info['json'])\n            traceback.print_exc()\n            return False, {\"msg\": self.event.last_info}\n        return True, image_list\n",
    "infer_image.MinioOper.__init__": "    def __init__(self, minio_info, context, event):\n        self.s3 = AWS_S3(**minio_info)\n        self.context = context\n        self.event = event\n",
    "infer_image.MinioOper.download_file": "    def download_file(self, local_dir, minio_path):\n        os.makedirs(local_dir, exist_ok=True)\n        file_name = os.path.basename(minio_path)\n        local_file_path = os.path.join(local_dir, file_name)\n\n        if os.path.exists(local_file_path):\n            return local_file_path\n        \n        try:\n            self.s3.download_file(minio_path, local_file_path)\n        except Exception as error:\n            self.event.info(f\"Download '{minio_path}' failed! Warning: {str(error)}\")\n            return ''\n        return local_file_path\n",
    "infer_image.MinioOper.download_image_annot": "    def download_image_annot(self, local_dir, img_group_name, img_group_info):\n        image_folder = os.path.join(local_dir, img_group_name)\n        os.makedirs(image_folder, exist_ok=True)\n        \n        ret = self.download_images(img_group_info[\"image_download_paths\"], image_folder)\n        if ret == False:\n            return DOWN_IMG_FAIL\n\n        return image_folder\n",
    "infer_image.MinioOper.download_images": "    def download_images(self, image_download_paths, save_image_folder):\n        for download_path in image_download_paths:\n            image_name = os.path.basename(download_path)\n            save_path = os.path.join(save_image_folder, image_name)\n            if os.path.exists(save_path):continue\n            try:\n                self.s3.download_file(download_path, save_path)\n            except Exception as error:\n                self.event.info(f\"Download '{download_path}' failed! Warning: {str(error)}\")\n                return False\n        return True\n",
    "infer_image.MinioOper.download_model_file": "    def download_model_file(self, local_models_dir, minio_model_filepath):\n        engine_folder = self.make_one_model_dir(local_models_dir, minio_model_filepath) # \u6a21\u578b\u540d\u5b57\u4e3a\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709json\n        if os.path.exists(engine_folder):\n            return True, engine_folder # \u6587\u4ef6\u5df2\u5b58\u5728\n        \n        model_zip_name = os.path.basename(minio_model_filepath)\n        model_zip_path = os.path.join(local_models_dir, model_zip_name)\n        \n        # \u4e0b\u8f7dzip\n        try:\n            self.s3.download_file(minio_model_filepath, model_zip_path)\n        except Exception as error:\n            self.event.info(f\"Download '{minio_model_filepath}' failed! Warning: {str(error)}\")\n            return False, engine_folder\n        \n        # \u89e3\u538b\n        if not self.unzip_file(model_zip_path, engine_folder):\n            self.event.info(f\"Unzip '{model_zip_path}' failed! Warning: {str(error)}\")\n            return False, engine_folder\n        os.remove(model_zip_path)\n\n        return True, engine_folder\n",
    "infer_image.MinioOper.make_one_model_dir": "    def make_one_model_dir(self, local_models_dir, minio_model_filepath):\n        model_zip_name = os.path.basename(minio_model_filepath)\n        model_zip_path = os.path.join(local_models_dir, model_zip_name)\n        one_model_dir = model_zip_path.replace('.zip', '')\n        return one_model_dir\n",
    "infer_image.MinioOper.move_file": "    def move_file(self, src_minio_path, dst_minio_path):\n        self.s3.move_file(src_minio_path, dst_minio_path)\n",
    "infer_image.MinioOper.unzip_file": "    def unzip_file(self, src_zip, target_dir=''):\n        '''\u521b\u5efa\u4e00\u4e2a\u538b\u7f29\u5305\u540c\u540d\u7684\u6587\u4ef6\u5939\u653e\u538b\u7f29\u5305\u5185\u5bb9'''\n        if not os.path.exists(src_zip):\n            return False\n\n        if target_dir == '':\n            target_dir = src_zip.replace('.zip', '')\n        os.makedirs(target_dir)\n\n        with zipfile.ZipFile(src_zip, 'r') as f:\n            for file in f.namelist():\n                f.extract(file, target_dir)\n\n        return True\n",
    "infer_image.MinioOper.upload_file": "    def upload_file(self, local_path, minio_dir):\n        minio_path = os.path.join(minio_dir, os.path.basename(local_path))\n\n        list_files = self.s3.get_content(minio_dir)\n        if minio_path.lstrip('/') in list_files:\n            self.event.info(f\"upload_file '{minio_path}' ready exist!\")\n            return True # \u6587\u4ef6\u5df2\u5b58\u5728\n        else:\n            if os.path.exists(local_path):\n                self.event.info(f\"upload_file '{local_path}' start!\")\n                return self.s3.upload_file(local_path, minio_path)\n            else:\n                self.event.info(f\"Error: upload_file '{minio_path}' error, local_path not exist: {local_path}!\")\n                return False\n",
    "infer_image.MinioOper.upload_json": "    def upload_json(self, dict_json, minio_dir, file_name=''):\n        tmp_path = os.path.join(TMP_DIR, '{}_{}.json'.format(file_name, get_time_now()))\n        os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n        with open(tmp_path, 'w', encoding='utf-8') as f:\n            content = json.dumps(dict_json, indent=4)\n            f.write(content)\n        \n        minio_path = os.path.join(minio_dir, os.path.basename(tmp_path))\n        return self.upload_file(tmp_path, minio_dir), minio_path\n",
    "infer_image.MinioOper.zip_folder": "    def zip_folder(self, src_dir, target_zip):\n        if not os.path.exists(src_dir):\n            print(f'zip_folder: src_dir not exist! {src_dir}')\n            return\n        \n        with zipfile.ZipFile(target_zip, 'w') as zipObj:\n            for filename in os.listdir(src_dir):\n                file_path = os.path.join(src_dir, filename)\n                # \u5c06\u6bcf\u4e2a\u6587\u4ef6\u6dfb\u52a0\u5230zip\u6587\u4ef6\u4e2d\n                zipObj.write(file_path, filename)\n",
    "infer_json.deepcopy": "def deepcopy(x, memo=None, _nil=[]):\n    \"\"\"Deep copy operation on arbitrary Python objects.\n\n    See the module's __doc__ string for more info.\n    \"\"\"\n\n    if memo is None:\n        memo = {}\n\n    d = id(x)\n    y = memo.get(d, _nil)\n    if y is not _nil:\n        return y\n\n    cls = type(x)\n\n    copier = _deepcopy_dispatch.get(cls)\n    if copier is not None:\n        y = copier(x, memo)\n    else:\n        if issubclass(cls, type):\n            y = _deepcopy_atomic(x, memo)\n        else:\n            copier = getattr(x, \"__deepcopy__\", None)\n            if copier is not None:\n                y = copier(memo)\n            else:\n                reductor = dispatch_table.get(cls)\n                if reductor:\n                    rv = reductor(x)\n                else:\n                    reductor = getattr(x, \"__reduce_ex__\", None)\n                    if reductor is not None:\n                        rv = reductor(4)\n                    else:\n                        reductor = getattr(x, \"__reduce__\", None)\n                        if reductor:\n                            rv = reductor()\n                        else:\n                            raise Error(\n                                \"un(deep)copyable object of type %s\" % cls)\n                if isinstance(rv, str):\n                    y = x\n                else:\n                    y = _reconstruct(x, memo, *rv)\n\n    # If is its own copy, don't memoize.\n    if y is not x:\n        memo[d] = y\n        _keep_alive(x, memo) # Make sure x lives at least as long as d\n    return y\n",
    "infer_json.InferJson.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "infer_json.InferJson.get_infer_image": "    def get_infer_image(self, model_name, image_info):\n        infer_image_info = deepcopy(image_info)\n        infer_params = image_info['image_infer_params'][model_name]\n        for key, value in infer_params.items():\n            infer_image_info[key] = deepcopy(value)\n        \n        return infer_image_info\n",
    "infer_json.InferJson.image_list_to_model_list": "    def image_list_to_model_list(self, image_list):\n        model_list = {}\n        for image_name, image_info in image_list.items():\n            image_infer_params = image_info['image_infer_params']\n            for model_name, model_info in image_infer_params.items():\n                if model_name not in model_list:\n                    model_list[model_name] = {}\n                infer_image_info = self.get_infer_image(model_name, image_info)\n                model_list[model_name][image_name] = infer_image_info\n        \n        return model_list\n",
    "infer_json.InferJson.merge_result_to_image_list": "    def merge_result_to_image_list(self, all_infer_result, image_list):\n        # \u63a8\u7406\u7ed3\u679c\u5408\u5e76\n        for model_name, result_list in all_infer_result.items():\n            for result in result_list:\n                image_name = result['image_name']\n                image_list[image_name]['image_infer_params'][model_name]['infer_result'] = deepcopy(result['labels'])\n        \n        # \u56fe\u7247\u8def\u5f84\u7b80\u5316\n        for image_info in image_list.values():\n            for i, path in enumerate(image_info['image_paths']):\n                image_info['image_paths'][i] = os.path.basename(path)\n",
    "infer_model.load_json": "def load_json(json_path):\n    try:\n        with open(json_path, \"r\", encoding=\"utf-8\") as fp:\n            json_data = orjson.loads(fp.read())\n    except:\n        json_data = {}\n    return json_data\n",
    "infer_model.ls_folder": "def ls_folder(folder, postfix=None, use_sort=True):\n    \"\"\"\n    \u5217\u51fa\u8f93\u5165folder\u4e0b\u9762\u7684\u6240\u6709\u6587\u4ef6\u76ee\u5f55\n    \"\"\"\n    os_sorted = natsort.os_sorted if use_sort else lambda x, *args, **kwargs: x\n    if os.path.exists(folder):\n        if postfix is None:\n            return os_sorted([os.path.join(folder, f) for f in os.listdir(folder)])\n        else:\n            if isinstance(postfix, str):\n                postfix = [postfix.upper()]\n            else:\n                postfix = [p.upper() for p in postfix]\n            return os_sorted([os.path.join(folder, f) for f in os.listdir(folder) if f[f.rfind(\".\")+1:].upper() in postfix])\n    else:\n        return []\n",
    "infer_model.Compose.__call__": "    def __call__(self, data: dict):\n        \"\"\"\u8c03\u7528\u51fd\u6570\u4ee5\u6309\u987a\u5e8f\u5e94\u7528\u56fe\u50cf\u589e\u5f3a\u53d8\u6362.\n        \u53c2\u6570:\n            data (dict): \u9700\u8981\u8f93\u5165\u7684\u6570\u636e.\n        Returns:\n           dict: \u5e8f\u5217\u5e94\u7528\u540e\u7684\u5b57\u5178\u683c\u5f0f.\n        \"\"\"\n        for t in self.modules:\n            data = t(**data)\n            if data is None:\n                return None\n        return data\n",
    "infer_model.Compose.__init__": "    def __init__(self, modules):\n        \"\"\"\n        \u987a\u5e8f\u6267\u884c\u7684\u6a21\u578b\u6a21\u7ec4\u7ba1\u9053\u6d41\u3002\n        \u53c2\u6570:\n            modules (Sequence[dict | callable])\uff1a\u987a\u5e8f\u6267\u884c\u7684\u6a21\u7ec4\n        \"\"\"\n        self.modules = []\n        for module in modules:\n            if isinstance(module, dict):\n                module = build_module(module)\n                self.modules.append(module)\n            elif callable(module):\n                self.modules.append(module)\n            else:\n                raise TypeError('modules \u5fc5\u987b\u662f\u4e00\u4e2a\u53ef\u4ee5\u88ab\u8c03\u7528\u7684\u5bf9\u8c61\u6216\u8005\u662f\u4e00\u4e2a\u5b57\u5178')\n",
    "infer_model.ETATimeIter.__init__": "    def __init__(self, iterable, callback_func_before_iter=[], callback_func_after_iter=[], event=None, **kwargs):\n        self.event = event\n        self.count = 0\n        self.used_time =0\n        self.t = 0\n        self.total_count = len(iterable)\n        self.iterable = iterable\n        self.callback_func_before_iter = callback_func_before_iter\n        self.callback_func_after_iter = callback_func_after_iter\n\n        # \u5982\u82e5\u4e0d\u5b58\u5728\u56de\u8c03\u51fd\u6570\uff0c\u5219\u4e0d\u6267\u884c\u8ba1\u65f6\n        self.enable = len(callback_func_before_iter) or len(callback_func_after_iter)\n        # \u6dfb\u52a0\u5176\u4f59\u53c2\u6570,\u5171\u56de\u8c03\u51fd\u6570\u4f7f\u7528\n        self._add_attr(**kwargs)\n",
    "infer_model.ETATimeIter.__iter__": "    def __iter__(self):\n        if self.enable:\n            self._init_time()\n            for obj in self.iterable:\n                self.before_iter()\n                yield obj\n                self._update_time()\n                self.after_iter()\n        else:\n            for obj in self.iterable:\n                yield obj\n",
    "infer_model.ETATimeIter.__len__": "    def __len__(self):\n        return len(self.iterable)\n",
    "infer_model.ETATimeIter._add_attr": "    def _add_attr(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n",
    "infer_model.ETATimeIter._init_time": "    def _init_time(self):\n        self.t = time.time()\n",
    "infer_model.ETATimeIter._update_time": "    def _update_time(self):\n        step_time = time.time()-self.t\n        self.t = time.time()\n        self.count += 1\n        self.used_time += step_time\n",
    "infer_model.ETATimeIter.after_iter": "    def after_iter(self):\n        for func in self.callback_func_after_iter:\n            func(self)\n",
    "infer_model.ETATimeIter.before_iter": "    def before_iter(self):\n        for func in self.callback_func_before_iter:\n            func(self, self.event)\n",
    "infer_model.InferDataset.__getitem__": "    def __getitem__(self, index):\n        image_name = self.image_names[index]\n        image_info = self.image_list[index]\n\n        detail_infos = image_info.get(\"detail_infos\", [])\n        image_paths = image_info[\"image_paths\"] + image_info.get(\"template_paths\", []) + image_info.get(\"gerber_paths\", [])\n        threshold = image_info.get(\"threshold\", None)\n        categories = image_info.get(\"categories\", None)\n        area = image_info.get(\"area\", None)\n        area_rule = image_info.get(\"area_rule\", None)   # [lower, upper]\n\n        images = read_images(image_paths, channels=self.image_channels)\n        return dict(image_name=image_name, images=images, image_paths=image_paths, threshold=threshold,\n                    categories=categories, detail_infos=detail_infos, area=area, area_rule=area_rule)\n",
    "infer_model.InferDataset.__init__": "    def __init__(self, images_data_info, image_channels, batch_size=32, **kwargs):\n        self.images_data_info = images_data_info\n        self.batch_size = batch_size\n        self.image_names = []\n        self.image_list = []\n        self.image_channels = image_channels\n        self.load_data()\n",
    "infer_model.InferDataset.__iter__": "    def __iter__(self):\n        data_list = []\n        for i in range(len(self.image_list)):\n            if i % self.batch_size == 0 and i != 0:\n                yield self.collect_data(data_list)\n                data_list = []\n            data = self[i]\n            data_list.append(data)\n        yield self.collect_data(data_list)\n",
    "infer_model.InferDataset.__len__": "    def __len__(self):\n        return len(self.image_list) // self.batch_size + 1 if len(self.image_list) % self.batch_size != 0 else \\\n            len(self.image_list) // self.batch_size\n",
    "infer_model.InferDataset.collect_data": "    @staticmethod\n    def collect_data(data_list: List[Dict]) -> Dict:\n        if len(data_list) == 0:\n            raise StopIteration\n        keys = list(data_list[0].keys())\n        data_info = dict()\n        for key in keys:\n            data_info[key] = [d.get(key)for d in data_list]\n        return data_info\n",
    "infer_model.InferDataset.load_data": "    def load_data(self):\n        for img_name, img_info in self.images_data_info.items():\n            self.image_names.append(img_name)\n            self.image_list.append(img_info)\n",
    "infer_model.InferModel.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "infer_model.InferModel.get_model_obj": "    def get_model_obj(self, oi_path, type='ONNX'):\n        print(f'Load type: {type}')\n        if type == 'TensorRT':\n            model = TRTInfer(oi_path)\n            # TRT\u8f6c\u5316\u7ed3\u679c\u4e0a\u4f20\u5230minio\n            if model.have_new_file:\n                self.upload_load_model_zip(oi_path)\n\n            return model\n        elif type == 'ONNX':\n            onnx_model = OnnxInfer(oi_path)\n            return onnx_model\n        else:\n            return None\n",
    "infer_model.InferModel.init_context_model": "    def init_context_model(self, local_models_dir, minio_info, minio_model_filepath, type):\n        # 1. \u4e0b\u8f7d\u6a21\u578b\u6587\u4ef6\n        self.mo = MinioOper(minio_info, self.context, self.event)\n        ret, engine_folder = self.mo.download_model_file(local_models_dir, minio_model_filepath) # \u4e0b\u8f7dzip\uff0c\u89e3\u538b\u5230\u5f53\u524d\u6587\u4ef6\u5939\uff0c\u5220\u9664zip\n        if not ret:\n            return False # \u4e0b\u8f7d\u5931\u8d25\n\n        model_name = os.path.basename(engine_folder)\n        self.event.info(f'Model init Begin...  (model_name={model_name})')\n        \n        # 2. \u83b7\u53d6json\u6587\u4ef6\u5e76\u63d0\u53d6\u76f8\u5173\u4fe1\u606f\n        json_path = ls_folder(engine_folder, \"json\")[0]\n        oi_path = ls_folder(engine_folder, \"oi\")[0]\n        json_info = load_json(json_path)\n        label_2_class = {i:label for i, label in enumerate(json_info[\"labels\"])}\n\n        # 3. \u83b7\u53d6\u7f51\u7edc\u6a21\u578b\u6587\u4ef6\u5e76\u521b\u5efa\u6a21\u578b\n        if type not in ['TensorRT', 'ONNX']:\n            type = 'ONNX'\n        model = self.get_model_obj(oi_path, type)\n\n        # 4. \u6d89\u53ca\u63a8\u7406\u7684\u6570\u636e\u52a0\u8f7d\u5230context\n        self.context.models[model_name] = {\n            'MODEL': model,\n            'LABEL_2_CLASS': label_2_class, # {0: 'NG', 1: 'OK'}\n            'THRESHOLD': json_info[\"threshold\"],\n            'JSON_INFO': json_info\n        }\n        \n        self.event.info(f'Model init Success! model_name={model_name}')\n        return True\n",
    "infer_model.InferModel.load": "    def load(self, model_name, type='ONNX'):\n        if model_name in self.context.models.keys():\n            return True\n        return self.init_context_model(self.context.MODELS_DIR, self.context.minio_info, f\"/models/{model_name}.zip\", type)\n",
    "infer_model.InferModel.upload_load_model_zip": "    def upload_load_model_zip(self, oi_path):\n        src_dir = os.path.dirname(oi_path)\n        zip_path = src_dir + '.zip'\n        self.mo.zip_folder(src_dir, zip_path)\n\n        src_minio_path = 'models/{}'.format(os.path.basename(zip_path))\n        dst_minio_path = 'models_backup/{}'.format(os.path.basename(zip_path))\n        self.mo.move_file(src_minio_path, dst_minio_path)\n\n        self.mo.upload_file(zip_path, 'models')\n",
    "infer_model.MinioOper.__init__": "    def __init__(self, minio_info, context, event):\n        self.s3 = AWS_S3(**minio_info)\n        self.context = context\n        self.event = event\n",
    "infer_model.MinioOper.download_file": "    def download_file(self, local_dir, minio_path):\n        os.makedirs(local_dir, exist_ok=True)\n        file_name = os.path.basename(minio_path)\n        local_file_path = os.path.join(local_dir, file_name)\n\n        if os.path.exists(local_file_path):\n            return local_file_path\n        \n        try:\n            self.s3.download_file(minio_path, local_file_path)\n        except Exception as error:\n            self.event.info(f\"Download '{minio_path}' failed! Warning: {str(error)}\")\n            return ''\n        return local_file_path\n",
    "infer_model.MinioOper.download_image_annot": "    def download_image_annot(self, local_dir, img_group_name, img_group_info):\n        image_folder = os.path.join(local_dir, img_group_name)\n        os.makedirs(image_folder, exist_ok=True)\n        \n        ret = self.download_images(img_group_info[\"image_download_paths\"], image_folder)\n        if ret == False:\n            return DOWN_IMG_FAIL\n\n        return image_folder\n",
    "infer_model.MinioOper.download_images": "    def download_images(self, image_download_paths, save_image_folder):\n        for download_path in image_download_paths:\n            image_name = os.path.basename(download_path)\n            save_path = os.path.join(save_image_folder, image_name)\n            if os.path.exists(save_path):continue\n            try:\n                self.s3.download_file(download_path, save_path)\n            except Exception as error:\n                self.event.info(f\"Download '{download_path}' failed! Warning: {str(error)}\")\n                return False\n        return True\n",
    "infer_model.MinioOper.download_model_file": "    def download_model_file(self, local_models_dir, minio_model_filepath):\n        engine_folder = self.make_one_model_dir(local_models_dir, minio_model_filepath) # \u6a21\u578b\u540d\u5b57\u4e3a\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709json\n        if os.path.exists(engine_folder):\n            return True, engine_folder # \u6587\u4ef6\u5df2\u5b58\u5728\n        \n        model_zip_name = os.path.basename(minio_model_filepath)\n        model_zip_path = os.path.join(local_models_dir, model_zip_name)\n        \n        # \u4e0b\u8f7dzip\n        try:\n            self.s3.download_file(minio_model_filepath, model_zip_path)\n        except Exception as error:\n            self.event.info(f\"Download '{minio_model_filepath}' failed! Warning: {str(error)}\")\n            return False, engine_folder\n        \n        # \u89e3\u538b\n        if not self.unzip_file(model_zip_path, engine_folder):\n            self.event.info(f\"Unzip '{model_zip_path}' failed! Warning: {str(error)}\")\n            return False, engine_folder\n        os.remove(model_zip_path)\n\n        return True, engine_folder\n",
    "infer_model.MinioOper.make_one_model_dir": "    def make_one_model_dir(self, local_models_dir, minio_model_filepath):\n        model_zip_name = os.path.basename(minio_model_filepath)\n        model_zip_path = os.path.join(local_models_dir, model_zip_name)\n        one_model_dir = model_zip_path.replace('.zip', '')\n        return one_model_dir\n",
    "infer_model.MinioOper.move_file": "    def move_file(self, src_minio_path, dst_minio_path):\n        self.s3.move_file(src_minio_path, dst_minio_path)\n",
    "infer_model.MinioOper.unzip_file": "    def unzip_file(self, src_zip, target_dir=''):\n        '''\u521b\u5efa\u4e00\u4e2a\u538b\u7f29\u5305\u540c\u540d\u7684\u6587\u4ef6\u5939\u653e\u538b\u7f29\u5305\u5185\u5bb9'''\n        if not os.path.exists(src_zip):\n            return False\n\n        if target_dir == '':\n            target_dir = src_zip.replace('.zip', '')\n        os.makedirs(target_dir)\n\n        with zipfile.ZipFile(src_zip, 'r') as f:\n            for file in f.namelist():\n                f.extract(file, target_dir)\n\n        return True\n",
    "infer_model.MinioOper.upload_file": "    def upload_file(self, local_path, minio_dir):\n        minio_path = os.path.join(minio_dir, os.path.basename(local_path))\n\n        list_files = self.s3.get_content(minio_dir)\n        if minio_path.lstrip('/') in list_files:\n            self.event.info(f\"upload_file '{minio_path}' ready exist!\")\n            return True # \u6587\u4ef6\u5df2\u5b58\u5728\n        else:\n            if os.path.exists(local_path):\n                self.event.info(f\"upload_file '{local_path}' start!\")\n                return self.s3.upload_file(local_path, minio_path)\n            else:\n                self.event.info(f\"Error: upload_file '{minio_path}' error, local_path not exist: {local_path}!\")\n                return False\n",
    "infer_model.MinioOper.upload_json": "    def upload_json(self, dict_json, minio_dir, file_name=''):\n        tmp_path = os.path.join(TMP_DIR, '{}_{}.json'.format(file_name, get_time_now()))\n        os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n        with open(tmp_path, 'w', encoding='utf-8') as f:\n            content = json.dumps(dict_json, indent=4)\n            f.write(content)\n        \n        minio_path = os.path.join(minio_dir, os.path.basename(tmp_path))\n        return self.upload_file(tmp_path, minio_dir), minio_path\n",
    "infer_model.MinioOper.zip_folder": "    def zip_folder(self, src_dir, target_zip):\n        if not os.path.exists(src_dir):\n            print(f'zip_folder: src_dir not exist! {src_dir}')\n            return\n        \n        with zipfile.ZipFile(target_zip, 'w') as zipObj:\n            for filename in os.listdir(src_dir):\n                file_path = os.path.join(src_dir, filename)\n                # \u5c06\u6bcf\u4e2a\u6587\u4ef6\u6dfb\u52a0\u5230zip\u6587\u4ef6\u4e2d\n                zipObj.write(file_path, filename)\n",
    "infer_model.OnnxInfer.__call__": "    def __call__(self, input_ts: list):\n        input_info = {name.name: data for name, data in zip(self.session.get_inputs(), input_ts)}\n        onnx_results = self.session.run([], input_info)\n        return onnx_results\n",
    "infer_model.OnnxInfer.__init__": "    def __init__(self, oi_file: str):\n        providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n\n        onnx_file = oi_file.replace(\".oi\", \".onnx\")\n        if os.path.exists(onnx_file):\n            self.session = onnxruntime.InferenceSession(onnx_file, providers=providers)\n            # self.session.set_providers(['CUDAExecutionProvider'], [ {'device_id': 0}]) # ONNX runtime\u6307\u5b9aGPU\n        elif os.path.exists(oi_file):\n            encrypt_file1_to_file2(oi_file, onnx_file, is_reverse=True)\n            self.session = onnxruntime.InferenceSession(onnx_file, providers=providers)\n            # self.session.set_providers(['CUDAExecutionProvider'], [ {'device_id': 0}]) # ONNX runtime\u6307\u5b9aGPU\n        else:\n            raise ValueError(f\"Can not file oi file and onnx file:{onnx_file}\")\n",
    "minio_oper.AWS_S3.__contains__": "    def __contains__(self, file_name):\n        return file_name in (item['name'] for item in self._files)\n",
    "minio_oper.AWS_S3.__init__": "    def __init__(self, bucket, region=None, access_key_id=None, secret_key=None, session_token=None, endpoint_url=None):\n        super().__init__()\n        if all([access_key_id, secret_key, session_token]):\n            self._s3 = boto3.resource(\n                's3',\n                aws_access_key_id=access_key_id,\n                aws_secret_access_key=secret_key,\n                aws_session_token=session_token,\n                region_name=region,\n                endpoint_url=endpoint_url\n            )\n        elif access_key_id and secret_key:\n            self._s3 = boto3.resource(\n                's3',\n                aws_access_key_id=access_key_id,\n                aws_secret_access_key=secret_key,\n                region_name=region,\n                endpoint_url=endpoint_url\n            )\n        elif any([access_key_id, secret_key, session_token]):\n            raise Exception('Insufficient data for authorization')\n        # anonymous access\n        if not any([access_key_id, secret_key, session_token]):\n            self._s3 = boto3.resource('s3', region_name=region, endpoint_url=endpoint_url)\n            self._s3.meta.client.meta.events.register('choose-signer.s3.*', disable_signing)\n        self._client_s3 = self._s3.meta.client\n        self._bucket = self._s3.Bucket(bucket)\n        self.region = region\n",
    "minio_oper.AWS_S3.__len__": "    def __len__(self):\n        return len(self._files)\n",
    "minio_oper.AWS_S3._head": "    def _head(self):\n        return self._client_s3.head_bucket(Bucket=self.name)\n",
    "minio_oper.AWS_S3._head_file": "    def _head_file(self, key):\n        return self._client_s3.head_object(Bucket=self.name, Key=key)\n",
    "minio_oper.AWS_S3.create": "    def create(self):\n        try:\n            responce = self._bucket.create(\n                ACL='private',\n                CreateBucketConfiguration={\n                    'LocationConstraint': self.region,\n                },\n                ObjectLockEnabledForBucket=False\n            )\n            print('Bucket {} has been created on {} region'.format(self.name, responce['Location']))\n        except Exception as ex:\n            msg = str(ex)\n            print(msg)\n            raise Exception(msg)\n",
    "minio_oper.AWS_S3.delete_objects": "    def delete_objects(self, object_name):\n        try:\n            delete_keys = {'Objects': []}\n            delete_keys['Objects'] = [{'Key': obj} for obj in object_name]\n            self._client_s3.delete_objects(Bucket=self.name, Delete=delete_keys)\n        except ClientError as e:\n            print(e)\n            return False\n        return True\n",
    "minio_oper.AWS_S3.download_file": "    def download_file(self, key, path):\n        file_obj = self.download_fileobj(key)\n        if isinstance(file_obj, BytesIO):\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            with open(path, 'wb') as f:\n                f.write(file_obj.getvalue())\n        else:\n            raise NotImplementedError(\"Unsupported type {} was found\".format(type(file_obj)))\n",
    "minio_oper.AWS_S3.download_fileobj": "    def download_fileobj(self, key):\n        key = key.replace(\"\\\\\", \"/\")\n        buf = BytesIO()\n        self.bucket.download_fileobj(\n            Key=key, Fileobj=buf, Config=TransferConfig(max_io_queue=self.transfer_config['max_io_queue'])\n        )\n        buf.seek(0)\n        return buf\n",
    "minio_oper.AWS_S3.get_content": "    def get_content(self, prefix=''):\n        if not prefix:\n            files = self._bucket.objects.all()\n        else:\n            files = self._bucket.objects.filter(Prefix=prefix.replace(\"\\\\\", \"/\"))\n        return [item.key for item in files]\n",
    "minio_oper.AWS_S3.get_file_last_modified": "    def get_file_last_modified(self, key):\n        return self._head_file(key).get('LastModified')\n",
    "minio_oper.AWS_S3.get_file_status": "    def get_file_status(self, key):\n        try:\n            self._head_file(key)\n            return 'AVAILABLE'\n        except ClientError as ex:\n            code = ex.response['Error']['Code']\n            if code == '403':\n                return 'FORBIDDEN'\n            else:\n                return 'NOT_FOUND'\n",
    "minio_oper.AWS_S3.get_status": "    def get_status(self):\n        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object\n        # return only 3 codes: 200, 403, 404\n        try:\n            self._head()\n            return 'AVAILABLE'\n        except ClientError as ex:\n            code = ex.response['Error']['Code']\n            if code == '403':\n                return 'FORBIDDEN'\n            else:\n                return 'NOT_FOUND'\n",
    "minio_oper.AWS_S3.initialize_content": "    def initialize_content(self, prefix=''):\n        files = self._bucket.objects.all()\n        self._files = [{\n            'name': item.key,\n        } for item in files if prefix == item.key[:len(prefix)]]\n",
    "minio_oper.AWS_S3.move_file": "    def move_file(self, src_key, dest_key):\n        # Copy the file\n        copy_source = {\n            'Bucket': self.name,\n            'Key': src_key\n        }\n        try:\n            self._client_s3.copy_object(Bucket=self.name, CopySource=copy_source, Key=dest_key)\n        except:\n            print('move fail.')\n            return\n        \n        # Delete the original file\n        self._client_s3.delete_object(Bucket=self.name, Key=src_key)\n",
    "minio_oper.AWS_S3.upload_file": "    def upload_file(self, file_name, object_name=None):\n        if object_name is None:\n            object_name = os.path.basename(file_name)\n\n        try:\n            self._client_s3.upload_file(file_name, self.name, object_name)\n        except ClientError as e:\n            print(e)\n            return False\n        return True\n",
    "minio_oper.AWS_S3.upload_fileobj": "    def upload_fileobj(self, file_obj, file_name):\n        self._bucket.upload_fileobj(\n            Fileobj=file_obj, Key=file_name, Config=TransferConfig(max_io_queue=self.transfer_config['max_io_queue'])\n        )\n",
    "minio_oper.MinioOper.__init__": "    def __init__(self, minio_info, context, event):\n        self.s3 = AWS_S3(**minio_info)\n        self.context = context\n        self.event = event\n",
    "minio_oper.MinioOper.download_file": "    def download_file(self, local_dir, minio_path):\n        os.makedirs(local_dir, exist_ok=True)\n        file_name = os.path.basename(minio_path)\n        local_file_path = os.path.join(local_dir, file_name)\n\n        if os.path.exists(local_file_path):\n            return local_file_path\n        \n        try:\n            self.s3.download_file(minio_path, local_file_path)\n        except Exception as error:\n            self.event.info(f\"Download '{minio_path}' failed! Warning: {str(error)}\")\n            return ''\n        return local_file_path\n",
    "minio_oper.MinioOper.download_image_annot": "    def download_image_annot(self, local_dir, img_group_name, img_group_info):\n        image_folder = os.path.join(local_dir, img_group_name)\n        os.makedirs(image_folder, exist_ok=True)\n        \n        ret = self.download_images(img_group_info[\"image_download_paths\"], image_folder)\n        if ret == False:\n            return DOWN_IMG_FAIL\n\n        return image_folder\n",
    "minio_oper.MinioOper.download_images": "    def download_images(self, image_download_paths, save_image_folder):\n        for download_path in image_download_paths:\n            image_name = os.path.basename(download_path)\n            save_path = os.path.join(save_image_folder, image_name)\n            if os.path.exists(save_path):continue\n            try:\n                self.s3.download_file(download_path, save_path)\n            except Exception as error:\n                self.event.info(f\"Download '{download_path}' failed! Warning: {str(error)}\")\n                return False\n        return True\n",
    "minio_oper.MinioOper.download_model_file": "    def download_model_file(self, local_models_dir, minio_model_filepath):\n        engine_folder = self.make_one_model_dir(local_models_dir, minio_model_filepath) # \u6a21\u578b\u540d\u5b57\u4e3a\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709json\n        if os.path.exists(engine_folder):\n            return True, engine_folder # \u6587\u4ef6\u5df2\u5b58\u5728\n        \n        model_zip_name = os.path.basename(minio_model_filepath)\n        model_zip_path = os.path.join(local_models_dir, model_zip_name)\n        \n        # \u4e0b\u8f7dzip\n        try:\n            self.s3.download_file(minio_model_filepath, model_zip_path)\n        except Exception as error:\n            self.event.info(f\"Download '{minio_model_filepath}' failed! Warning: {str(error)}\")\n            return False, engine_folder\n        \n        # \u89e3\u538b\n        if not self.unzip_file(model_zip_path, engine_folder):\n            self.event.info(f\"Unzip '{model_zip_path}' failed! Warning: {str(error)}\")\n            return False, engine_folder\n        os.remove(model_zip_path)\n\n        return True, engine_folder\n",
    "minio_oper.MinioOper.make_one_model_dir": "    def make_one_model_dir(self, local_models_dir, minio_model_filepath):\n        model_zip_name = os.path.basename(minio_model_filepath)\n        model_zip_path = os.path.join(local_models_dir, model_zip_name)\n        one_model_dir = model_zip_path.replace('.zip', '')\n        return one_model_dir\n",
    "minio_oper.MinioOper.move_file": "    def move_file(self, src_minio_path, dst_minio_path):\n        self.s3.move_file(src_minio_path, dst_minio_path)\n",
    "minio_oper.MinioOper.unzip_file": "    def unzip_file(self, src_zip, target_dir=''):\n        '''\u521b\u5efa\u4e00\u4e2a\u538b\u7f29\u5305\u540c\u540d\u7684\u6587\u4ef6\u5939\u653e\u538b\u7f29\u5305\u5185\u5bb9'''\n        if not os.path.exists(src_zip):\n            return False\n\n        if target_dir == '':\n            target_dir = src_zip.replace('.zip', '')\n        os.makedirs(target_dir)\n\n        with zipfile.ZipFile(src_zip, 'r') as f:\n            for file in f.namelist():\n                f.extract(file, target_dir)\n\n        return True\n",
    "minio_oper.MinioOper.upload_file": "    def upload_file(self, local_path, minio_dir):\n        minio_path = os.path.join(minio_dir, os.path.basename(local_path))\n\n        list_files = self.s3.get_content(minio_dir)\n        if minio_path.lstrip('/') in list_files:\n            self.event.info(f\"upload_file '{minio_path}' ready exist!\")\n            return True # \u6587\u4ef6\u5df2\u5b58\u5728\n        else:\n            if os.path.exists(local_path):\n                self.event.info(f\"upload_file '{local_path}' start!\")\n                return self.s3.upload_file(local_path, minio_path)\n            else:\n                self.event.info(f\"Error: upload_file '{minio_path}' error, local_path not exist: {local_path}!\")\n                return False\n",
    "minio_oper.MinioOper.upload_json": "    def upload_json(self, dict_json, minio_dir, file_name=''):\n        tmp_path = os.path.join(TMP_DIR, '{}_{}.json'.format(file_name, get_time_now()))\n        os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n        with open(tmp_path, 'w', encoding='utf-8') as f:\n            content = json.dumps(dict_json, indent=4)\n            f.write(content)\n        \n        minio_path = os.path.join(minio_dir, os.path.basename(tmp_path))\n        return self.upload_file(tmp_path, minio_dir), minio_path\n",
    "minio_oper.MinioOper.zip_folder": "    def zip_folder(self, src_dir, target_zip):\n        if not os.path.exists(src_dir):\n            print(f'zip_folder: src_dir not exist! {src_dir}')\n            return\n        \n        with zipfile.ZipFile(target_zip, 'w') as zipObj:\n            for filename in os.listdir(src_dir):\n                file_path = os.path.join(src_dir, filename)\n                # \u5c06\u6bcf\u4e2a\u6587\u4ef6\u6dfb\u52a0\u5230zip\u6587\u4ef6\u4e2d\n                zipObj.write(file_path, filename)\n",
    "test.test_download_images": "def test_download_images(images_data_info={\"zip\": \"images/Img-none-251.zip\", \"json\": \"images/Img-none-5-model_id.json\"}):\n    infer_image = InferImage(context, event)\n\n    is_ok, image_list = infer_image.download_infer_images(context.minio_info, images_data_info)\n    return image_list, infer_image\n",
    "test.test_infer_exec": "def test_infer_exec(model_name, infer_image_list):\n    model = {\n        'infer_model_name': model_name, \n        'infer_param': {\n            'OK': {'lower_threshold': 0.5, 'upper_threshold': 0.5},\n            'NG': {'lower_threshold': 0.5, 'upper_threshold': 0.5}\n        }\n    }\n\n    infer_exec = InferExec(context, event)\n    list_infer_result = infer_exec.infer_classifier(model, infer_image_list)\n    return list_infer_result\n",
    "test.test_infer_json": "def test_infer_json(image_list):\n    infer_json = InferJson(context, event)\n    model_list = infer_json.image_list_to_model_list(image_list)\n    return model_list\n",
    "test.test_init_model": "def test_init_model(model_name='classification_cls_test_test_m_2023-04-04-08-14-48'):\n    infer_model = InferModel(context, event)\n    ret = infer_model.load(model_name)\n    return ret\n",
    "test.InferContext.__init__": "    def __init__(self):\n        self.models = {}\n        self.minio_info = {\n            \"bucket\": os.getenv('INFER_MINIO_bucket', 'infer'),\n            \"access_key_id\": os.getenv('INFER_MINIO_access_key_id', 'deepsight'),\n            \"secret_key\": os.getenv('INFER_MINIO_secret_key', 'deepsight'),\n            \"endpoint_url\": os.getenv('INFER_MINIO_endpoint_url', 'http://172.29.10.42:9001/')\n        }\n        self.WORKSPACE = './'\n        self.MODELS_DIR = os.path.join(self.WORKSPACE, 'models_dir')\n        self.TMP_DIR = os.path.join(self.WORKSPACE, 'tmp')\n",
    "test.InferContext.delete_model": "    def delete_model(self, model_name):\n        if model_name in self.models:\n            # \u5220\u9664\u5185\u5b58\u4e2d\u6570\u636e\n            self.models.pop(model_name)\n        \n        one_model_dir = os.path.join(self.MODELS_DIR, model_name)\n        if os.path.exists(one_model_dir):\n            # \u5220\u9664\u78c1\u76d8\u4e2d\u6587\u4ef6\n            shutil.rmtree(one_model_dir)\n\n        return True\n",
    "test.InferContext.get_model_list": "    def get_model_list(self):\n        return list(self.models.keys())\n",
    "test.InferEvent.__init__": "    def __init__(self, body={}, path='/classifier-many-model', method='POST', job_id=''):\n        self.body = body\n        self.path = path\n        self.method = method\n        self.post_log = PostLog(job_id)\n\n        self.last_info = ''\n",
    "test.InferEvent.info": "    def info(self, log_text):\n        self.last_info = log_text\n        self.post_log('INFO', log_text)\n",
    "test.InferEvent.test_init": "    def test_init(self):\n        data = [\n            {\n                'infer_model_name': 'classification_cls_test_test_m_2023-03-31-02-35-27',\n                'infer_param': {\n                    'OK': {'lower_threshold': 0.5, 'upper_threshold': 0.5},\n                    'NG': {'lower_threshold': 0.5, 'upper_threshold': 0.5}\n                },\n                'minio_info': {\n                    'bucket': 'infer',\n                    'access_key_id': 'minio',\n                    'secret_key': 'deepsight',\n                    'endpoint_url': 'http://172.29.10.135:9001/'\n                },\n                'data_info': {\n                    \"59e248ec-ddb7-11ed-b21f-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 1}\n                    },\n                    \"59e248ed-ddb7-11ed-9782-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 0}\n                    },\n                    \"59e248ee-ddb7-11ed-9ae6-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 0}\n                    },\n                    \"59e248ef-ddb7-11ed-81a4-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 1}\n                    },\n                    \"59e248f0-ddb7-11ed-b0e9-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0.5, \"NG\": 0.5}\n                    }\n                }\n            },\n            {\n                'infer_model_name': 'classification_cls_test_test_m_2023-04-04-08-14-48',\n                'infer_param': {\n                    'OK': {'lower_threshold': 0.5, 'upper_threshold': 0.5},\n                    'NG': {'lower_threshold': 0.5, 'upper_threshold': 0.5}\n                },\n                'minio_info': {\n                    'bucket': 'infer',\n                    'access_key_id': 'minio',\n                    'secret_key': 'deepsight',\n                    'endpoint_url': 'http://172.29.10.135:9001/'\n                },\n                'image_base_dir': '',\n                'image_list': {\n                    \"59e248ec-ddb7-11ed-b21f-34735ac51bd8\": {\n                        \"image_zip_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 1}\n                    },\n                    \"59e248ed-ddb7-11ed-9782-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 0}\n                    },\n                    \"59e248ee-ddb7-11ed-9ae6-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0, \"NG\": 0}\n                    },\n                    \"59e248ef-ddb7-11ed-81a4-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 1, \"NG\": 1}\n                    },\n                    \"59e248f0-ddb7-11ed-b0e9-34735ac51bd8\": {\n                        \"image_download_paths\": [\n                            \"none/59e248ec-ddb7-11ed-b21f-34735ac51bd8/2022100617131601530Y-NK-pcs1-vrs0-2.png\"\n                        ],\n                        \"label_threshold\":{\"OK\": 0.5, \"NG\": 0.5}\n                    }\n                }\n            }\n        ]\n\n        self.body = data\n        self.path = '/classifier-many-model'\n        self.method = 'POST'\n",
    "test.InferExec.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "test.InferExec.infer_classifier": "    def infer_classifier(self, model, infer_image_list, batch_size=32):\n        infer_model_name = model['infer_model_name']\n        infer_param = model['infer_param']\n        self.event.info('infer_classifier:model=' + str(model))\n        \n        # \u83b7\u5f97\u6a21\u578b\n        infer_model = InferModel(self.context, self.event)\n        if infer_model.load(infer_model_name, 'ONNX'): # \u9ed8\u8ba4ONNX\uff0c\u9632\u6b62TensorRT\u673a\u578b\u4e0d\u517c\u5bb9\n            model_obj = self.context.models[infer_model_name]\n        else:\n            self.event.info(f'Error: model not exist. {infer_model_name}')\n            return False, {\"msg\": self.event.last_info}\n\n        # \u83b7\u53d6\u5404\u7c7b\u63a8\u7406\u65b9\u6cd5\n        json_info = model_obj['JSON_INFO']\n        # self.event.info('infer_classifier:json_info=' + str(json_info))\n        category, lower_threshold, upper_threshold = self.parse_model_json_info(json_info)\n        self.event.info('infer_classifier:category=' + str(category))\n        result_name = f\"FilterByModel_{infer_model_name}\"\n\n        cfg = list()\n        cfg.append(dict(\n            type=\"FilterByModel\",\n            json_info=json_info,\n            category=category, # [\"OK\", \"NG\"],\n            lower_threshold=lower_threshold, # [0.5, 0.3],\n            upper_threshold=upper_threshold, # [0.5, 0.7],\n            infer_model=model_obj['MODEL'],\n            name=result_name\n            )\n        )\n        # \u521b\u5efa\u63a8\u7406\u7ba1\u9053\n        filter_pipeline = Compose(cfg)\n\n        # \u521b\u5efa\u63a8\u7406\u7684\u6570\u636e\u96c6\n        self.label_threshold_to_array(infer_image_list) # \u5b57\u5178\u8f6c\u5217\u8868\n        self.event.info('infer_classifier:batch_size=' + str(batch_size))\n        dataset = InferDataset(infer_image_list, json_info[\"images_channel\"], batch_size=int(batch_size))\n        eta_iter = ETATimeIter(dataset, [print_info], interval=10, event=self.event)\n\n        try:\n            list_infer_result = []\n            for data in eta_iter:\n                result = filter_pipeline(data)\n                list_infer_result += result[result_name]\n        except:\n            error_msg = traceback.format_exc()\n            if 'len(image_path_list) == len(channels)' in error_msg:\n                error_msg = 'The images do not match the model.'\n            self.event.info(f'Error: model infer fail. {error_msg}')\n            return False, {\"msg\": self.event.last_info}\n\n        return True, list_infer_result\n",
    "test.InferExec.label_threshold_to_array": "    def label_threshold_to_array(self, infer_image_list):\n        for image_info in infer_image_list.values():\n            image_info['categories'] = list(image_info['label_threshold'].keys())\n            image_info['threshold'] = list(image_info['label_threshold'].values())\n",
    "test.InferExec.parse_infer_param": "    def parse_infer_param(self, infer_param):\n        category, lower_threshold, upper_threshold = [], [], []\n        for label, threshold in infer_param.items():\n            category.append(label)\n            lower_threshold.append(threshold['lower_threshold'])\n            upper_threshold.append(threshold['upper_threshold'])\n        return category, lower_threshold, upper_threshold\n",
    "test.InferExec.parse_model_json_info": "    def parse_model_json_info(self, json_info):\n        category = json_info['labels'] # [\"ok\", \"ng\"]\n        lower_threshold = [0.5] * len(category)\n        upper_threshold = [0.5] * len(category)\n        return category, lower_threshold, upper_threshold\n",
    "test.InferImage.__del__": "    def __del__(self):\n        self.clear_tmp_images_dir()\n",
    "test.InferImage.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n        self.tmp_images_dir = os.path.join(self.context.TMP_DIR, 'tmp_images/%s' % str(uuid.uuid1()))\n",
    "test.InferImage.clear_tmp_images_dir": "    def clear_tmp_images_dir(self):\n        if os.path.exists(self.tmp_images_dir):\n            shutil.rmtree(self.tmp_images_dir)\n",
    "test.InferImage.download_infer_images": "    def download_infer_images(self, minio_info, images_data_info):\n        '''\n        \"images_data_info\": {\n            \"zip\": \"images/Img-none-251.zip\",\n            \"json\": \"images/Img-none-5-model_id.json\"\n        }\n        '''\n        mo = MinioOper(minio_info, self.context, self.event)\n        if not ('zip' in images_data_info.keys() and 'json' in images_data_info.keys()):\n            self.event.info(f'Param Error. images_data_info requires both zip and json fields.')\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u4e0b\u8f7djson\u3001zip\n        local_zip_path = mo.download_file(self.tmp_images_dir, images_data_info['zip'])\n        local_json_path = mo.download_file(self.tmp_images_dir, images_data_info['json'])\n        if local_zip_path == '':\n            self.event.info(f'File download fail: %s' % local_zip_path)\n            return False, {\"msg\": self.event.last_info}\n        if local_json_path == '':\n            self.event.info(f'File download fail: %s' % local_json_path)\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u89e3\u538bzip\n        local_image_dir = local_zip_path.replace('.zip', '')\n        if mo.unzip_file(local_zip_path, local_image_dir):\n            self.event.info(f'local_image_dir: %s' % local_image_dir)\n        else:\n            self.event.info(f'File not found: %s' % local_zip_path)\n            return False, {\"msg\": self.event.last_info}\n        \n        # \u89e3\u6790json\uff0c\u83b7\u53d6\u672c\u5730\u56fe\u7247\u8def\u5f84\u3001\u56fe\u7247\u540d\u79f0\u3001\u53c2\u6570\n        try:\n            with open(local_json_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                self.event.info('Image Json(%s): \\n%s ......' % (images_data_info['json'], content[:300]))\n                image_list = json.loads(content)\n                for image_name, image_info in image_list.items():\n                    for i, path in enumerate(image_info['image_paths']):\n                        image_list[image_name]['image_paths'][i] = os.path.join(local_image_dir, path)\n                    if 'template_paths' in image_info:\n                        for i, path in enumerate(image_info['template_paths']):\n                            image_list[image_name]['template_paths'][i] = os.path.join(local_image_dir, path)\n                    if 'gerber_paths' in image_info:\n                        for i, path in enumerate(image_info['gerber_paths']):\n                            image_list[image_name]['gerber_paths'][i] = os.path.join(local_image_dir, path)\n        except:\n            self.event.info(f'Image Json(%s): Content error.' % images_data_info['json'])\n            traceback.print_exc()\n            return False, {\"msg\": self.event.last_info}\n        return True, image_list\n",
    "test.InferJson.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "test.InferJson.get_infer_image": "    def get_infer_image(self, model_name, image_info):\n        infer_image_info = deepcopy(image_info)\n        infer_params = image_info['image_infer_params'][model_name]\n        for key, value in infer_params.items():\n            infer_image_info[key] = deepcopy(value)\n        \n        return infer_image_info\n",
    "test.InferJson.image_list_to_model_list": "    def image_list_to_model_list(self, image_list):\n        model_list = {}\n        for image_name, image_info in image_list.items():\n            image_infer_params = image_info['image_infer_params']\n            for model_name, model_info in image_infer_params.items():\n                if model_name not in model_list:\n                    model_list[model_name] = {}\n                infer_image_info = self.get_infer_image(model_name, image_info)\n                model_list[model_name][image_name] = infer_image_info\n        \n        return model_list\n",
    "test.InferJson.merge_result_to_image_list": "    def merge_result_to_image_list(self, all_infer_result, image_list):\n        # \u63a8\u7406\u7ed3\u679c\u5408\u5e76\n        for model_name, result_list in all_infer_result.items():\n            for result in result_list:\n                image_name = result['image_name']\n                image_list[image_name]['image_infer_params'][model_name]['infer_result'] = deepcopy(result['labels'])\n        \n        # \u56fe\u7247\u8def\u5f84\u7b80\u5316\n        for image_info in image_list.values():\n            for i, path in enumerate(image_info['image_paths']):\n                image_info['image_paths'][i] = os.path.basename(path)\n",
    "test.InferModel.__init__": "    def __init__(self, context, event):\n        self.context = context\n        self.event = event\n",
    "test.InferModel.get_model_obj": "    def get_model_obj(self, oi_path, type='ONNX'):\n        print(f'Load type: {type}')\n        if type == 'TensorRT':\n            model = TRTInfer(oi_path)\n            # TRT\u8f6c\u5316\u7ed3\u679c\u4e0a\u4f20\u5230minio\n            if model.have_new_file:\n                self.upload_load_model_zip(oi_path)\n\n            return model\n        elif type == 'ONNX':\n            onnx_model = OnnxInfer(oi_path)\n            return onnx_model\n        else:\n            return None\n",
    "test.InferModel.init_context_model": "    def init_context_model(self, local_models_dir, minio_info, minio_model_filepath, type):\n        # 1. \u4e0b\u8f7d\u6a21\u578b\u6587\u4ef6\n        self.mo = MinioOper(minio_info, self.context, self.event)\n        ret, engine_folder = self.mo.download_model_file(local_models_dir, minio_model_filepath) # \u4e0b\u8f7dzip\uff0c\u89e3\u538b\u5230\u5f53\u524d\u6587\u4ef6\u5939\uff0c\u5220\u9664zip\n        if not ret:\n            return False # \u4e0b\u8f7d\u5931\u8d25\n\n        model_name = os.path.basename(engine_folder)\n        self.event.info(f'Model init Begin...  (model_name={model_name})')\n        \n        # 2. \u83b7\u53d6json\u6587\u4ef6\u5e76\u63d0\u53d6\u76f8\u5173\u4fe1\u606f\n        json_path = ls_folder(engine_folder, \"json\")[0]\n        oi_path = ls_folder(engine_folder, \"oi\")[0]\n        json_info = load_json(json_path)\n        label_2_class = {i:label for i, label in enumerate(json_info[\"labels\"])}\n\n        # 3. \u83b7\u53d6\u7f51\u7edc\u6a21\u578b\u6587\u4ef6\u5e76\u521b\u5efa\u6a21\u578b\n        if type not in ['TensorRT', 'ONNX']:\n            type = 'ONNX'\n        model = self.get_model_obj(oi_path, type)\n\n        # 4. \u6d89\u53ca\u63a8\u7406\u7684\u6570\u636e\u52a0\u8f7d\u5230context\n        self.context.models[model_name] = {\n            'MODEL': model,\n            'LABEL_2_CLASS': label_2_class, # {0: 'NG', 1: 'OK'}\n            'THRESHOLD': json_info[\"threshold\"],\n            'JSON_INFO': json_info\n        }\n        \n        self.event.info(f'Model init Success! model_name={model_name}')\n        return True\n",
    "test.InferModel.load": "    def load(self, model_name, type='ONNX'):\n        if model_name in self.context.models.keys():\n            return True\n        return self.init_context_model(self.context.MODELS_DIR, self.context.minio_info, f\"/models/{model_name}.zip\", type)\n",
    "test.InferModel.upload_load_model_zip": "    def upload_load_model_zip(self, oi_path):\n        src_dir = os.path.dirname(oi_path)\n        zip_path = src_dir + '.zip'\n        self.mo.zip_folder(src_dir, zip_path)\n\n        src_minio_path = 'models/{}'.format(os.path.basename(zip_path))\n        dst_minio_path = 'models_backup/{}'.format(os.path.basename(zip_path))\n        self.mo.move_file(src_minio_path, dst_minio_path)\n\n        self.mo.upload_file(zip_path, 'models')\n"
}